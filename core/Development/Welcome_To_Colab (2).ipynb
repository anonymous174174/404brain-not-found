{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JkdP6sXmSoX",
        "outputId": "049a0c4d-939a-4382-e456-c62fa2cbdf9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rustworkx\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from rustworkx) (2.0.2)\n",
            "Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rustworkx\n",
            "Successfully installed rustworkx-0.16.0\n"
          ]
        }
      ],
      "source": [
        "! pip install rustworkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ulR6Lvv1lxRA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFj9utaNld3a"
      },
      "source": [
        "# custom Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Zyo4n4MclcEK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class CustomTensor:\n",
        "    \"\"\"\n",
        "    CustomTensor(data, ...) will return the same object if `data` is already a CustomTensor.\n",
        "    This avoids memory reallocation and graph duplication.\n",
        "    Do not use it to rewrap or re-register nodes. Use only for symbolic reference.\n",
        "    \"\"\"\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph','__weakref__')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None,due_to_operation=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data  # ✅ Prevent new allocation, return existing one\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None,due_to_operation=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            # Already returned in __new__, skip init\n",
        "            return\n",
        "        if due_to_operation:\n",
        "          self.tensor = data\n",
        "        else:\n",
        "          self.tensor = torch.as_tensor(data, dtype=dtype, device=device)\n",
        "          self.tensor.requires_grad_(False)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "\n",
        "        if _custom_requires_grad:\n",
        "            self._init_graph(graph)\n",
        "\n",
        "    def _init_graph(self, graph):\n",
        "        if graph is None:\n",
        "            raise ValueError(\"Graph must be provided when _custom_requires_grad is True.\")\n",
        "        self.graph = weakref.ref(graph)\n",
        "        graph.add_tensor_graph(self)\n",
        "        graph.add_non_leaf_tensor_references(self)\n",
        "    def _zero_grad(self):\n",
        "        self.tensor.grad = torch.zeros_like(self.tensor)\n",
        "\n",
        "    def __add__(self,other):\n",
        "\n",
        "        if isinstance(other, numbers.Number):\n",
        "            result = Operations.add_tensor_and_scalar(self.tensor,other)\n",
        "            requires_grad = self._custom_requires_grad\n",
        "            if requires_grad:\n",
        "                graph = self.graph()\n",
        "                result = CustomTensor(result,_custom_requires_grad=True,graph=graph,due_to_operation=True)\n",
        "                graph.add_edge(self._node_id, result._node_id)\n",
        "                def _backward():\n",
        "                    if self.tensor.grad is None:\n",
        "                        self._zero_grad()\n",
        "                    self.tensor.grad = Operations.add_tensor_and_tensor(self.tensor.grad,result.tensor.grad)\n",
        "                result._backward = _backward\n",
        "                return result\n",
        "            else:\n",
        "                return CustomTensor(result,_custom_requires_grad=requires_grad)\n",
        "        elif isinstance(other,CustomTensor):\n",
        "            result = Operations.add_tensor_and_tensor(self.tensor,other.tensor)\n",
        "            self_requires_grad = self._custom_requires_grad\n",
        "            other_requires_grad = other._custom_requires_grad\n",
        "            if self_requires_grad and other_requires_grad:\n",
        "                graph = self.graph()\n",
        "                result = CustomTensor(result,_custom_requires_grad=True,graph=graph,due_to_operation=True)\n",
        "                graph.add_edge(self._node_id, result._node_id)\n",
        "                graph.add_edge(other._node_id, result._node_id)\n",
        "                def _backward():\n",
        "                    if self.tensor.grad is None:\n",
        "                        self._zero_grad()\n",
        "                    if other.tensor.grad is None:\n",
        "                        other._zero_grad()\n",
        "                    self.tensor.grad.add_(result.tensor.grad)\n",
        "                    other.tensor.grad.add_(result.tensor.grad)\n",
        "                result._backward = _backward\n",
        "                return result\n",
        "            elif self_requires_grad and not other_requires_grad:\n",
        "                graph =self.graph()\n",
        "                result = CustomTensor(result,_custom_requires_grad = True, graph=graph,due_to_operation=True)\n",
        "                graph.add_edge(self._node_id,result._node_id)\n",
        "                def _backward():\n",
        "                    if self.tensor.grad is None:\n",
        "                        self._zero_grad()\n",
        "                    self.tensor.grad.add_(result.tensor.grad)# = Operations.add_tensor_and_tensor(self.tensor.grad,result.tensor.grad)\n",
        "                result._backward =_backward\n",
        "                return result\n",
        "            elif other_requires_grad and not self_requires_grad:\n",
        "                graph = other.graph()\n",
        "                result = CustomTensor(result,_custom_requires_grad =True, graph = graph,due_to_operation=True)\n",
        "                graph.add_edge(other._node_id,result._node_id)\n",
        "                def _backward():\n",
        "                    if other.tensor.grad is None:\n",
        "                        other._zero_grad()\n",
        "                    other.tensor.grad.add_(result.tensor.grad) #= Operations.add_tensor_and_tensor(other.tensor.grad,result.tensor.grad)\n",
        "                result._backward =_backward\n",
        "                return result\n",
        "            else:\n",
        "                return CustomTensor(result,_custom_requires_grad=False,graph=None,due_to_operation=True)\n",
        "    def __del__(self):\n",
        "        print(f\"CustomTensor with id={id(self)} is being garbage collected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wctU5vHZlhfL"
      },
      "source": [
        "# AutogradGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GN6M4TQFlmwM"
      },
      "outputs": [],
      "source": [
        "class AutogradGraph:\n",
        "    def __init__(self,check_for_cycles=True, auto_cleanup=True):\n",
        "        self.graph = rx.PyDiGraph()\n",
        "        self.intermediate_tensors = dict()\n",
        "        self._check_cycles = check_for_cycles\n",
        "        self._auto_cleanup = auto_cleanup\n",
        "\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._check_cycles:\n",
        "            if not self.check_cycle():\n",
        "                raise RuntimeError(\"Cycle detected in autograd graph on context exit.\")\n",
        "        if self._auto_cleanup:\n",
        "            self.intermediate_tensors.clear()\n",
        "            self.graph.clear()\n",
        "\n",
        "    def add_tensor_graph(self, tensor):\n",
        "        requires_grad = tensor._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            raise ValueError(\"Tensor with require grad False cannot to be added to the graph.\")\n",
        "\n",
        "        tensor_index = self.graph.add_node(weakref.ref(tensor))\n",
        "        tensor._node_id  = tensor_index\n",
        "\n",
        "    def add_non_leaf_tensor_references(self, tensor):\n",
        "        requires_grad = tensor._custom_requires_grad\n",
        "\n",
        "        node_id = tensor._node_id\n",
        "\n",
        "        if not requires_grad:\n",
        "            raise ValueError(\"Tensor must be a non leaf tensor.\")\n",
        "\n",
        "        if node_id in self.intermediate_tensors:\n",
        "            raise ValueError(\"Tensor reference to persist in memory already exists.\")\n",
        "\n",
        "        self.intermediate_tensors[node_id] = tensor\n",
        "\n",
        "    def add_edge(self, node_from, node_to, weight=None):\n",
        "        if not isinstance(node_from, int) or not isinstance(node_to, int):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "\n",
        "        graph = self.graph\n",
        "        if not graph.has_node(node_from) or not graph.has_node(node_to):\n",
        "            raise ValueError(\"Both nodes must exist in the graph before adding an edge.\")\n",
        "\n",
        "        graph.add_edge(node_from, node_to, weight)\n",
        "\n",
        "    def check_cycle(self):\n",
        "        return rx.is_directed_acyclic_graph(self.graph)\n",
        "\n",
        "    def reverse_toposort(self):\n",
        "\n",
        "        if not self.check_cycle():\n",
        "            raise RuntimeError(\"Cannot perform topological sort on a graph with cycles.\")\n",
        "        graph = self.graph\n",
        "        node_indexes = rx.topological_sort(graph)\n",
        "        return [graph[node_index] for node_index in reversed(node_indexes)]\n",
        "\n",
        "    def delete_node(self, node_index):\n",
        "        if not isinstance(node_index, int):\n",
        "            raise TypeError(\"Node index must be an integer.\")\n",
        "\n",
        "        graph = self.graph\n",
        "        if not graph.has_node(node_index):\n",
        "            raise ValueError(f\"Node index {node_index} does not exist in the graph.\")\n",
        "\n",
        "        graph.remove_node(node_index)\n",
        "\n",
        "    def delete_edge(self, node_from, node_to):\n",
        "        if not isinstance(node_from, int) or not isinstance(node_to, int):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "\n",
        "        graph = self.graph\n",
        "        if not graph.has_edge(node_from, node_to):\n",
        "            raise ValueError(f\"Edge ({node_from}, {node_to}) does not exist in the graph.\")\n",
        "\n",
        "        graph.remove_edge(node_from, node_to)\n",
        "\n",
        "    def del_non_leaf_tensor_reference(self, tensor_node_id):\n",
        "        try:\n",
        "            del self.intermediate_tensors[tensor_node_id]\n",
        "        except KeyError:\n",
        "            raise KeyError(f\"No tensor reference found for node ID {tensor_node_id}\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        graph = self.graph\n",
        "        return f\"CustomAutogradGraph(nodes={graph.num_nodes()}, edges={graph.num_edges()})\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eqsMV42lnfh"
      },
      "source": [
        "# Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "FkA57SKdlpUJ"
      },
      "outputs": [],
      "source": [
        "class Operations:\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_scalar(tensor: torch.Tensor, scaler: float) -> torch.Tensor:\n",
        "        return tensor + scaler\n",
        "\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor1 + tensor2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEdjOowPmgZ-"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XnNWDQWtme0s"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "dtype =  torch.float16\n",
        "a = CustomTensor([1,2,3],_custom_requires_grad=False,device=\"cpu\",dtype=dtype,graph = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "kbQPucrMEpz7"
      },
      "outputs": [],
      "source": [
        "b = CustomTensor([-5,6.8,-3.5],_custom_requires_grad=False,device = device,dtype=dtype,graph = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzH1083JE7vu",
        "outputId": "ab78e940-ce53-4ec0-f033-3620612a50b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x78a842ead350>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlX4MIS7rW-p",
        "outputId": "3ee5b965-b470-4372-c0ff-f576e20be642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x78a842ad2750>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ChS1tzQr84E",
        "outputId": "70d79387-dd10-460c-98bd-5ba3a120cf7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.], dtype=torch.float16)"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.tensor.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "MZLnqJQsHiv5"
      },
      "outputs": [],
      "source": [
        "a._zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kKXynC8H5El",
        "outputId": "244c5f26-a5c9-41fb-b6b7-449d1551a6fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.], dtype=torch.float16)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.tensor.grad.add_(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "-yPyYqlWE96d"
      },
      "outputs": [],
      "source": [
        "c=a+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlbuVFyLHSO1",
        "outputId": "2d355207-5ae6-4fc8-bd28-bc0b6650c2bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-4.0000,  8.7969, -0.5000], dtype=torch.float16)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1OhLpKHVJj",
        "outputId": "d5ed4e04-0292-4f48-8108-b36d1bab4f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x78a842b328e0>"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ObERoNbAHWMn"
      },
      "outputs": [],
      "source": [
        "d=c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dZr8Vp1HXEV",
        "outputId": "c7ee1a6e-e283-4478-d5fd-c71b2730ae17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x78a842b328e0>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "LjWyo2qXoWm-"
      },
      "outputs": [],
      "source": [
        "k=CustomTensor(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fmEKvtSrlOa",
        "outputId": "5c95d9f4-7d8d-4988-8042-c8eaab002335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float16)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k.tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEl3Xrj1u5WU",
        "outputId": "2fe5d151-8387-4bb4-a348-2cbb96f28f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x78a861876f20>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "MR1V5liRDvk-"
      },
      "outputs": [],
      "source": [
        "k=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "UiKj_s8CEbvz"
      },
      "outputs": [],
      "source": [
        "del a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sZL89CWED6Z-"
      },
      "outputs": [],
      "source": [
        "a=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "vtk2H0-4ES7S"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9O1vGfHvZHU",
        "outputId": "d959b26d-39a1-4588-ab7d-0b480a55f09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.getrefcount(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "5JpEC2NnvhlI"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtUC5Ly3vjFz",
        "outputId": "a703bbac-b815-434c-c31f-80f2caf066c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "eDfwBP41uyA4"
      },
      "outputs": [],
      "source": [
        "k=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "bIvuQ3Xju0rL"
      },
      "outputs": [],
      "source": [
        "del a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z_Wh9bsVpljS"
      },
      "outputs": [],
      "source": [
        "k=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kswkZWYep2J6",
        "outputId": "453f71e3-3ade-451a-b653-d98433a45e75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x7bdc07166ed0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa5SncS0pnIG",
        "outputId": "cc91be06-9788-4dd3-e525-bbc46d886c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CustomTensor at 0x7979064d74c0>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C`ustomTensor(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wsoA6-woXCF",
        "outputId": "19400a38-1082-4178-a613-6005cbd6d1bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float16)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQLLFJWapHti",
        "outputId": "0992b15f-ad49-4958-97c0-a0bb23bb0c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ref count after a: 2\n",
            "Ref count after k: 3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import weakref\n",
        "\n",
        "class CustomTensor:\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return\n",
        "        self.tensor = torch.as_tensor(data, dtype=dtype, device=device)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "\n",
        "a = CustomTensor([1,2,3], _custom_requires_grad=False, device=\"cpu\", dtype=torch.float16, graph=None)\n",
        "print(\"Ref count after a:\", sys.getrefcount(a))\n",
        "\n",
        "k = CustomTensor(a)\n",
        "print(\"Ref count after k:\", sys.getrefcount(a))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46H4koJCY40y"
      },
      "source": [
        "# testing reference and weakref.proxy use case possibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvzZ4DZuXsv_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx\n",
        "\n",
        "class Operations:\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "        return tensor + scalar\n",
        "\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor1 + tensor2\n",
        "\n",
        "class AutogradGraph:\n",
        "    def __init__(self, check_for_cycles=True, auto_cleanup=True):\n",
        "        self.graph = rx.PyDiGraph()\n",
        "        self.intermediate_tensors = {}\n",
        "        self._check_cycles = check_for_cycles\n",
        "        self._auto_cleanup = auto_cleanup\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._check_cycles and not self.check_cycle():\n",
        "            raise RuntimeError(\"Cycle detected in autograd graph on context exit.\")\n",
        "        if self._auto_cleanup:\n",
        "            self.intermediate_tensors.clear()\n",
        "            self.graph.clear()\n",
        "\n",
        "    def add_tensor_graph(self, tensor, is_leaf):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor with requires_grad=False cannot be added to the graph.\")\n",
        "\n",
        "        ref = tensor if is_leaf else weakref.proxy(tensor)\n",
        "        tensor_index = self.graph.add_node(ref)\n",
        "        tensor._node_id = tensor_index\n",
        "\n",
        "    def add_non_leaf_tensor_reference(self, tensor):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor must require grad.\")\n",
        "\n",
        "        if tensor._node_id in self.intermediate_tensors:\n",
        "            raise ValueError(\"Tensor reference already exists in intermediate tensors.\")\n",
        "\n",
        "        self.intermediate_tensors[tensor._node_id] = tensor\n",
        "\n",
        "    def add_edge(self, node_from, node_to, weight=None):\n",
        "        if not all(isinstance(n, int) for n in (node_from, node_to)):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "        if not self.graph.has_node(node_from) or not self.graph.has_node(node_to):\n",
        "            raise ValueError(\"Nodes must exist before adding edge.\")\n",
        "        self.graph.add_edge(node_from, node_to, weight)\n",
        "\n",
        "    def check_cycle(self):\n",
        "        return rx.is_directed_acyclic_graph(self.graph)\n",
        "\n",
        "    def reverse_toposort(self):\n",
        "        if not self.check_cycle():\n",
        "            raise RuntimeError(\"Cannot perform topological sort on cyclic graph.\")\n",
        "        return [self.graph[n] for n in reversed(rx.topological_sort(self.graph))]\n",
        "\n",
        "    def delete_node(self, node_index):\n",
        "        if not isinstance(node_index, int):\n",
        "            raise TypeError(\"Node index must be an integer.\")\n",
        "        if not self.graph.has_node(node_index):\n",
        "            raise ValueError(\"Node does not exist.\")\n",
        "        self.graph.remove_node(node_index)\n",
        "\n",
        "    def delete_edge(self, node_from, node_to):\n",
        "        if not self.graph.has_edge(node_from, node_to):\n",
        "            raise ValueError(\"Edge does not exist.\")\n",
        "        self.graph.remove_edge(node_from, node_to)\n",
        "\n",
        "    def del_non_leaf_tensor_reference(self, tensor_node_id):\n",
        "        self.intermediate_tensors.pop(tensor_node_id, None)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CustomAutogradGraph(nodes={self.graph.num_nodes()}, edges={self.graph.num_edges()})\"\n",
        "\n",
        "class CustomTensor:\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph', '__weakref__')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data  # Don't rewrap\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return\n",
        "\n",
        "        self.tensor = data if due_to_operation else torch.as_tensor(data, dtype=dtype, device=device)\n",
        "        self.tensor.requires_grad_(False)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "\n",
        "        if _custom_requires_grad:\n",
        "            self._init_graph(graph, is_leaf)\n",
        "\n",
        "    def _init_graph(self, graph, is_leaf):\n",
        "        if graph is None:\n",
        "            raise ValueError(\"Graph must be provided if requires_grad is True.\")\n",
        "        self.graph = weakref.proxy(graph)\n",
        "        graph.add_tensor_graph(self, is_leaf=is_leaf)\n",
        "        if not is_leaf:\n",
        "            graph.add_non_leaf_tensor_reference(self)\n",
        "\n",
        "    def _zero_grad(self):\n",
        "        self.tensor.grad = torch.zeros_like(self.tensor)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._binary_op_scalar(other, op=Operations.add_tensor_and_scalar)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._binary_op_tensor(other, op=Operations.add_tensor_and_tensor)\n",
        "        return NotImplemented\n",
        "\n",
        "    def _binary_op_scalar(self, scalar, op):\n",
        "        result_tensor = op(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result.tensor.grad)\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _binary_op_tensor(self, other, op):\n",
        "        result_tensor = op(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result.tensor.grad)\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result.tensor.grad)\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def __del__(self):\n",
        "        print(f\"CustomTensor with id={id(self)} is being garbage collected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmpTbqadYn47"
      },
      "source": [
        "# working build 7th july"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYdGgt65Yo1t"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'base (Python 3.13.2)' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx\n",
        "import pytest\n",
        "\n",
        "# Original code (assuming it's in a file named 'autograd_system.py' or similar)\n",
        "# For the purpose of this test code, I'll include it directly.\n",
        "\n",
        "class Operations:\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "        return tensor + scalar\n",
        "\n",
        "    @torch.jit.script\n",
        "    def add_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor1 + tensor2\n",
        "\n",
        "    @torch.jit.script\n",
        "    def mul_tensor_and_scaler(tensor: torch.Tensor, scaler: float) -> torch.Tensor:\n",
        "        return tensor * scaler\n",
        "\n",
        "    @torch.jit.script\n",
        "    def mul_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor1 * tensor2\n",
        "\n",
        "    @torch.jit.script\n",
        "    def sub_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "        return tensor - scalar\n",
        "\n",
        "    @torch.jit.script\n",
        "    def sub_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor1 - tensor2\n",
        "\n",
        "    @torch.jit.script\n",
        "    def div_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "        return tensor / scalar\n",
        "\n",
        "    @torch.jit.script\n",
        "    def pow_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "        return tensor.pow(scalar)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def exp_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.exp(tensor)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def log_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.log(tensor)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def sin_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.sin(tensor)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def cos_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.cos(tensor)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def dot_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.dot(tensor1, tensor2)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def apply_binary_mask(tensor: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "        return tensor * mask\n",
        "\n",
        "    @torch.jit.script\n",
        "    def sqrt_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.sqrt(tensor)\n",
        "\n",
        "    @torch.jit.script\n",
        "    def matmul_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.matmul(tensor1, tensor2)\n",
        "\n",
        "    def einsum(equation: str, *operands) -> torch.Tensor:\n",
        "        # torch.jit.script does not support variable arguments or string arguments well,\n",
        "        # so einsum cannot be scripted. Leave as a static method.\n",
        "        return torch.einsum(equation, *operands)\n",
        "\n",
        "class AutogradGraph:\n",
        "    def __init__(self, check_for_cycles=True, auto_cleanup=True):\n",
        "        self.graph = rx.PyDiGraph()\n",
        "        self.intermediate_tensors = {}\n",
        "        self._check_cycles = check_for_cycles\n",
        "        self._auto_cleanup = auto_cleanup\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._check_cycles and not self.check_cycle():\n",
        "            raise RuntimeError(\"Cycle detected in autograd graph on context exit.\")\n",
        "        if self._auto_cleanup:\n",
        "            self.intermediate_tensors.clear()\n",
        "            self.graph.clear()\n",
        "\n",
        "    def add_tensor_graph(self, tensor, is_leaf):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor with requires_grad=False cannot be added to the graph.\")\n",
        "\n",
        "        ref = tensor if is_leaf else weakref.proxy(tensor)\n",
        "        tensor_index = self.graph.add_node(ref)\n",
        "        tensor._node_id = tensor_index\n",
        "\n",
        "    def add_non_leaf_tensor_reference(self, tensor):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor must require grad.\")\n",
        "\n",
        "        if tensor._node_id in self.intermediate_tensors:\n",
        "            raise ValueError(\"Tensor reference already exists in intermediate tensors.\")\n",
        "\n",
        "        self.intermediate_tensors[tensor._node_id] = tensor\n",
        "\n",
        "    def add_edge(self, node_from, node_to, weight=None):\n",
        "        if not all(isinstance(n, int) for n in (node_from, node_to)):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "        if not self.graph.has_node(node_from) or not self.graph.has_node(node_to):\n",
        "            raise ValueError(\"Nodes must exist before adding edge.\")\n",
        "        self.graph.add_edge(node_from, node_to, weight)\n",
        "\n",
        "    def check_cycle(self):\n",
        "        return rx.is_directed_acyclic_graph(self.graph)\n",
        "\n",
        "    def reverse_toposort(self):\n",
        "        if not self.check_cycle():\n",
        "            raise RuntimeError(\"Cannot perform topological sort on cyclic graph.\")\n",
        "        # rustworkx.topological_sort already works on node indices and dependencies\n",
        "        # The result of rx.topological_sort is a list of node indices in topological order.\n",
        "        # We then retrieve the actual tensor objects using self.graph[n].\n",
        "        return [self.graph[n] for n in reversed(rx.topological_sort(self.graph))]\n",
        "\n",
        "    def delete_node(self, node_index):\n",
        "        if not isinstance(node_index, int):\n",
        "            raise TypeError(\"Node index must be an integer.\")\n",
        "        if not self.graph.has_node(node_index):\n",
        "            raise ValueError(\"Node does not exist.\")\n",
        "        self.graph.remove_node(node_index)\n",
        "\n",
        "    def delete_edge(self, node_from, node_to):\n",
        "        if not self.graph.has_edge(node_from, node_to):\n",
        "            raise ValueError(\"Edge does not exist.\")\n",
        "        self.graph.remove_edge(node_from, node_to)\n",
        "\n",
        "    def del_non_leaf_tensor_reference(self, tensor_node_id):\n",
        "        self.intermediate_tensors.pop(tensor_node_id, None)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CustomAutogradGraph(nodes={self.graph.num_nodes()}, edges={self.graph.num_edges()})\"\n",
        "\n",
        "class CustomTensor:\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph', '__weakref__')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data  # Don't rewrap\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return\n",
        "\n",
        "        self.tensor = data if due_to_operation else torch.as_tensor(data, dtype=dtype, device=device)\n",
        "        self.tensor.requires_grad_(False)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "\n",
        "        if _custom_requires_grad:\n",
        "            self._init_graph(graph, is_leaf)\n",
        "\n",
        "    def _init_graph(self, graph, is_leaf):\n",
        "        if graph is None:\n",
        "            raise ValueError(\"Graph must be provided if requires_grad is True.\")\n",
        "        if is_leaf:\n",
        "          self.graph = weakref.proxy(graph)\n",
        "        else:\n",
        "          self.graph = graph\n",
        "        graph.add_tensor_graph(self, is_leaf=is_leaf)\n",
        "        if not is_leaf:\n",
        "            graph.add_non_leaf_tensor_reference(self)\n",
        "\n",
        "    def _zero_grad(self):\n",
        "        self.tensor.grad = torch.zeros_like(self.tensor)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._binary_op_scalar(other, op=Operations.add_tensor_and_scalar)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._binary_op_tensor(other, op=Operations.add_tensor_and_tensor)\n",
        "        return NotImplemented\n",
        "\n",
        "    def _binary_op_scalar(self, scalar, op):\n",
        "        result_tensor = op(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            # print(f\"Backward for scalar add: result_grad={result.tensor.grad}, self_grad_before={self_ref.tensor.grad}\") # Debugging\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "            # print(f\"Backward for scalar add: self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _binary_op_tensor(self, other, op):\n",
        "        result_tensor = op(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        # Graph selection logic - assuming operations happen within a single graph context\n",
        "        graph = None\n",
        "        if self._custom_requires_grad:\n",
        "            graph = self.graph\n",
        "        elif other._custom_requires_grad:\n",
        "            graph = other.graph\n",
        "        else:\n",
        "            # This case should ideally not be reached if requires_grad is True\n",
        "            # and at least one operand has requires_grad\n",
        "            pass # Or raise an error if graph is truly missing\n",
        "\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            # print(f\"Backward for tensor add: result_grad={result.tensor.grad}\") # Debugging\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  other_grad_after={other_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def __mul__(self,other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._binary_op_scalar(other, op=Operations.add_tensor_and_scalar)\n",
        "        if isinstance(other, CustomTensor):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __del__(self):\n",
        "        # print(f\"CustomTensor with node_id={self._node_id} (id={id(self)}) is being garbage collected\") # Debugging\n",
        "        pass # Suppress print for cleaner test output\n",
        "\n",
        "\n",
        "# --- Test Code ---\n",
        "\n",
        "def run_backward(output_tensor: CustomTensor):\n",
        "    \"\"\"\n",
        "    Simulates the backward pass for the custom autograd system.\n",
        "    This function needs to be explicitly defined as it's not part of the original classes.\n",
        "    \"\"\"\n",
        "    if not output_tensor._custom_requires_grad:\n",
        "        raise RuntimeError(\"Output tensor does not require grad.\")\n",
        "    if output_tensor.graph is None:\n",
        "        raise RuntimeError(\"Output tensor is not part of a graph.\")\n",
        "\n",
        "    # Initialize gradient for the output tensor\n",
        "    output_tensor.tensor.grad = torch.ones_like(output_tensor.tensor)\n",
        "\n",
        "    # Perform backward pass using topological sort\n",
        "    nodes_to_process = output_tensor.graph.reverse_toposort()\n",
        "\n",
        "    # Create a strong reference to intermediate tensors needed for backward pass\n",
        "    # This simulates how a real autograd engine would keep track of them\n",
        "    # The graph context's intermediate_tensors dict already serves this purpose.\n",
        "\n",
        "    for tensor_node in nodes_to_process:\n",
        "        # Check if the weak proxy is still valid (tensor is alive)\n",
        "        if isinstance(tensor_node, weakref.ProxyTypes) and tensor_node.__slots__ is None:\n",
        "            # print(f\"Skipping dead proxy: {tensor_node}\") # Debugging\n",
        "            continue # Skip if the weak reference is dead\n",
        "\n",
        "        if tensor_node.tensor.grad is None and tensor_node is not output_tensor:\n",
        "            # This can happen if a tensor is part of the graph but its grad hasn't been set yet\n",
        "            # and it's not the root of the backward call. This typically means it's a leaf\n",
        "            # that wasn't used to compute the output or an intermediate that accumulated no grad.\n",
        "            # For simplicity in this test, we assume grads propagate.\n",
        "            # print(f\"Warning: Tensor node {tensor_node._node_id} has no grad before _backward call.\")\n",
        "            pass # A no-op for now. In a real system, you might want to handle this.\n",
        "\n",
        "        # Ensure that non-leaf tensors are still alive when their _backward is called\n",
        "        # The `intermediate_tensors` in `AutogradGraph` should keep them alive.\n",
        "        tensor_node._backward()\n",
        "\n",
        "    # Clean up intermediate tensors references after backward pass\n",
        "    # This would typically be handled by the graph context's exit, but\n",
        "    # if `_auto_cleanup` is False, you might need manual cleanup.\n",
        "    # Here, for testing GC, we'll let the context manager handle it.\n",
        "\n",
        "\n",
        "class TestCustomAutogradSystem:\n",
        "\n",
        "    def test_basic_add_scalar_grad(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = a + 5.0 # (a + 5)\n",
        "            c = b + 10.0 # (a + 5 + 10)\n",
        "\n",
        "            # Manually run backward pass\n",
        "            run_backward(c)\n",
        "\n",
        "            # Expected gradients:\n",
        "            # dC/dA = 1.0 (for each element)\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert b.tensor.grad is not None\n",
        "            assert torch.allclose(b.tensor.grad, torch.tensor([1.0, 1.0])) # dC/dB = 1.0\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 3\n",
        "            assert graph.graph.num_edges() == 2\n",
        "            assert graph.graph.has_edge(a._node_id, b._node_id)\n",
        "            assert graph.graph.has_edge(b._node_id, c._node_id)\n",
        "            assert graph.check_cycle() is True\n",
        "\n",
        "    def test_basic_add_tensor_grad(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([1.0, 2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            c = a + b # (a + b)\n",
        "            d = c + 5.0 # (a + b + 5)\n",
        "\n",
        "            run_backward(d)\n",
        "\n",
        "            # Expected gradients:\n",
        "            # dD/dA = 1.0\n",
        "            # dD/dB = 1.0\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert torch.allclose(b.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 4\n",
        "            assert graph.graph.num_edges() == 3\n",
        "            assert graph.graph.has_edge(a._node_id, c._node_id)\n",
        "            assert graph.graph.has_edge(b._node_id, c._node_id)\n",
        "            assert graph.graph.has_edge(c._node_id, d._node_id)\n",
        "            assert graph.check_cycle() is True\n",
        "\n",
        "    def test_mixed_requires_grad_tensor_add(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([1.0, 2.0]), _custom_requires_grad=False) # Does not require grad\n",
        "            c = a + b # c should require grad, b's grad should be None\n",
        "\n",
        "            run_backward(c)\n",
        "\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert b.tensor.grad is None # b should not have a grad\n",
        "            assert c._custom_requires_grad is True\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 2 # Only a and c in the graph\n",
        "            assert graph.graph.num_edges() == 1\n",
        "            assert graph.graph.has_node(a._node_id)\n",
        "            assert graph.graph.has_node(c._node_id)\n",
        "            assert graph.graph.has_edge(a._node_id, c._node_id)\n",
        "            #assert not graph.graph.has_node(b._node_id) # b should not be in graph\n",
        "\n",
        "    def test_no_requires_grad(self):\n",
        "        with AutogradGraph() as graph: # Graph created, but no tensors with requires_grad=True added\n",
        "            a = CustomTensor(torch.tensor([1.0]))\n",
        "            b = CustomTensor(torch.tensor([2.0]))\n",
        "            c = a + b\n",
        "            d = c + 3.0\n",
        "\n",
        "            assert not a._custom_requires_grad\n",
        "            assert not b._custom_requires_grad\n",
        "            assert not c._custom_requires_grad\n",
        "            assert not d._custom_requires_grad\n",
        "            assert graph.graph.num_nodes() == 0 # Graph should remain empty\n",
        "            assert graph.graph.num_edges() == 0\n",
        "\n",
        "            with pytest.raises(RuntimeError, match=\"Output tensor does not require grad.\"):\n",
        "                run_backward(d)\n",
        "\n",
        "    def test_autograd_graph_context_manager(self):\n",
        "        graph = None\n",
        "        with AutogradGraph(check_for_cycles=True, auto_cleanup=True) as g:\n",
        "            graph = g\n",
        "            a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = a + 1.0\n",
        "            assert graph.graph.num_nodes() == 2\n",
        "            assert graph.graph.num_edges() == 1\n",
        "            assert len(graph.intermediate_tensors) == 1 # b should be in intermediate_tensors\n",
        "\n",
        "        # After exiting the context, graph should be empty\n",
        "        assert graph.graph.num_nodes() == 0\n",
        "        assert graph.graph.num_edges() == 0\n",
        "        assert len(graph.intermediate_tensors) == 0\n",
        "\n",
        "    def test_cycle_detection(self):\n",
        "      try:\n",
        "        with AutogradGraph(check_for_cycles=True, auto_cleanup=False) as graph: # auto_cleanup=False to inspect after error\n",
        "            a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "\n",
        "            # Manually create a cycle (a -> b -> a)\n",
        "            graph.add_edge(a._node_id, b._node_id)\n",
        "            graph.add_edge(b._node_id, a._node_id)\n",
        "      except RuntimeError as e:\n",
        "        print(f\"Raised the error of cycle detected as {e}\")\n",
        "            # with pytest.raises(RuntimeError, match=\"Cycle detected in autograd graph on context exit.\"):\n",
        "            #     pass # The __exit__ method will be called here\n",
        "\n",
        "    def test_no_circular_references_non_leaf_tensors_die(self):\n",
        "          # This test relies on the garbage collector. It's a heuristic test\n",
        "        # as Python's GC timing is not strictly deterministic.\n",
        "        # However, with weakrefs, it should work for non-leaf tensors.\n",
        "\n",
        "      print(\"\\n--- Starting GC Test: No Circular References (Part 1) ---\")\n",
        "\n",
        "      graph_ref = None\n",
        "      output_tensor_weak_ref = None\n",
        "      node_id_d = -1 # To store node_id before d is deleted\n",
        "\n",
        "      # BLOCK 1: Create graph and tensors\n",
        "      with AutogradGraph(auto_cleanup=False) as graph: # Keep graph for inspection\n",
        "          graph_ref = weakref.ref(graph)\n",
        "          a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "          b = a + 1.0 # Intermediate tensor\n",
        "          c = b + 2.0 # Intermediate tensor\n",
        "          d = c + 3.0 # Output tensor (also intermediate from graph's perspective)\n",
        "\n",
        "          # Store weak reference to 'd' BEFORE its strong reference is potentially removed\n",
        "          output_tensor_weak_ref = weakref.ref(d)\n",
        "          node_id_d = d._node_id # Store node_id while d is alive\n",
        "\n",
        "          print(f\"Initial: d object: {d}\")\n",
        "          print(f\"Initial: d._node_id: {node_id_d}\")\n",
        "          print(f\"Initial: graph.intermediate_tensors keys: {list(graph.intermediate_tensors.keys())}\")\n",
        "          # The ref count for `d` object itself will be high here because it's in `graph.intermediate_tensors`,\n",
        "          # and held by variable `d`, and by the temporary ref in `getrefcount`.\n",
        "          print(f\"Initial: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'}\")\n",
        "          assert len(graph.intermediate_tensors) == 3 # b, c, d should be in intermediate_tensors\n",
        "\n",
        "      # BLOCK 2: After exiting context manager (auto_cleanup=False)\n",
        "      print(\"\\n--- After exiting 'with' block (auto_cleanup=False) ---\")\n",
        "      # The 'graph' variable still holds a strong reference to the AutogradGraph instance.\n",
        "      # graph_ref() should return the graph object.\n",
        "      assert graph_ref() is not None, \"Graph object should still be alive.\"\n",
        "      assert len(graph_ref().intermediate_tensors) == 3, \"Intermediate tensors should still be referenced by the graph.\"\n",
        "      print(f\"After 'with' block: d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      print(f\"After 'with' block: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref())}\")\n",
        "\n",
        "      # BLOCK 3: Remove strong reference 'd' from local scope\n",
        "      print(\"\\n--- Deleting 'd' variable ---\")\n",
        "      del d # Remove the local strong reference to the CustomTensor object.\n",
        "      gc.collect() # Force garbage collection\n",
        "\n",
        "      # Now, output_tensor_weak_ref() *still* shouldn't be None because `graph_ref().intermediate_tensors`\n",
        "      # holds the strong reference.\n",
        "      print(f\"After del d + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      # We expect this to *not* be None yet, and to still show a refcount reflecting intermediate_tensors.\n",
        "      assert output_tensor_weak_ref() is not None, \"d should still be alive due to intermediate_tensors.\"\n",
        "      current_d_refcount_after_del_d = sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'\n",
        "      print(f\"After del d + gc.collect(): refcount of d: {current_d_refcount_after_del_d}\")\n",
        "      # Expected refcount should be 2: one from intermediate_tensors, one from getrefcount()\n",
        "      assert current_d_refcount_after_del_d == 2, f\"Expected refcount 2, got {current_d_refcount_after_del_d}\"\n",
        "\n",
        "      # BLOCK 4: Remove strong reference from intermediate_tensors\n",
        "      print(f\"\\n--- Deleting strong reference from graph.intermediate_tensors for node {node_id_d} ---\")\n",
        "      graph_ref().del_non_leaf_tensor_reference(node_id_d) # THIS IS THE CRUCIAL STEP\n",
        "      print(f\"After del_non_leaf_tensor_reference: graph.intermediate_tensors keys: {list(graph_ref().intermediate_tensors.keys())}\")\n",
        "      #gc.collect() # Force garbage collection again\n",
        "\n",
        "      # Now, with the last strong reference gone, 'd' should be garbage collected.\n",
        "      print(f\"After del_non_leaf_tensor_reference + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      # This is where your original assertion was. It *should* pass now.\n",
        "      assert output_tensor_weak_ref() is None, \"Output tensor (non-leaf) should be garbage collected after its strong reference is deleted from intermediate_tensors.\"\n",
        "      print(\"Assertion Passed: Output tensor (d) was garbage collected.\")\n",
        "\n",
        "      # BLOCK 5: Verify other intermediate tensors are collected when graph is cleared\n",
        "      print(\"\\n--- Starting GC Test: All Intermediate Tensors ---\")\n",
        "      intermediate_tensors_wrefs = []\n",
        "      # Create a new graph and new tensors to avoid interference from previous block\n",
        "      with AutogradGraph(auto_cleanup=False) as graph_new:\n",
        "          a_new = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph_new, is_leaf=True)\n",
        "          b_new = a_new + 1.0 # Intermediate\n",
        "          c_new = b_new + 2.0 # Intermediate\n",
        "          d_new = c_new + 3.0 # Intermediate (output of a chain)\n",
        "\n",
        "          # Store weak references to the intermediate tensors\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(b_new))\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(c_new))\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(d_new))\n",
        "\n",
        "          # Verify they are initially alive\n",
        "          assert all(wref() is not None for wref in intermediate_tensors_wrefs)\n",
        "          assert len(graph_new.intermediate_tensors) == 3\n",
        "\n",
        "      print(f\"After 'with' block (new graph): graph_new object: {graph_new}\")\n",
        "      assert graph_new is not None, \"New graph object should still be alive after 'with' block.\"\n",
        "      assert len(graph_new.intermediate_tensors) == 3, \"New graph intermediate_tensors should still hold refs.\"\n",
        "\n",
        "      # Manually clear the intermediate_tensors dictionary and remove graph reference\n",
        "      print(\"\\n--- Manually clearing graph.intermediate_tensors and deleting graph ---\")\n",
        "      graph_new.intermediate_tensors.clear()\n",
        "      del graph_new # Remove the strong reference to the graph itself\n",
        "      del b_new , c_new , d_new # deleting the local variable strong references\n",
        "      #gc.collect()\n",
        "\n",
        "      # Now, all non-leaf tensors should be garbage collected\n",
        "      for i, wref in enumerate(intermediate_tensors_wrefs):\n",
        "          print(f\"Intermediate tensor {i} (via weakref): {wref()}\")\n",
        "          assert wref() is None, f\"Intermediate tensor {i} should be garbage collected after graph context and intermediate_tensors are cleared.\"\n",
        "      print(\"Assertion Passed: All intermediate tensors were garbage collected.\")\n",
        "\n",
        "    def test_topological_sort_order(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            t1 = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            t2 = CustomTensor(torch.tensor([2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            t3 = t1 + t2\n",
        "            t4 = t3 + 5.0\n",
        "            t5 = t2 + 10.0 # Another branch\n",
        "            t6 = t4 + t5\n",
        "\n",
        "            # The topological sort should produce an order where dependencies come before their dependents.\n",
        "            # Reversed topological sort should produce an order where outputs come before their inputs.\n",
        "            # Example expected order: t6, t4, t5, t3, t2, t1 (or variations respecting dependencies)\n",
        "            sorted_tensors = graph.reverse_toposort()\n",
        "\n",
        "            # Check if dependencies are respected in reverse order\n",
        "            # If A -> B, then B should appear before A in reverse topological sort.\n",
        "            # t6 depends on t4, t5. So t6 should be before t4 and t5.\n",
        "            # t4 depends on t3. So t4 should be before t3.\n",
        "            # t5 depends on t2. So t5 should be before t2.\n",
        "            # t3 depends on t1, t2. So t3 should be before t1 and t2.\n",
        "\n",
        "            # Simple check: The first element should be t6 (the ultimate output).\n",
        "            assert sorted_tensors[0] is t6\n",
        "\n",
        "            # Check positions:\n",
        "            pos = {t: i for i, t in enumerate(sorted_tensors)}\n",
        "\n",
        "            assert pos[t6] < pos[t4]\n",
        "            assert pos[t6] < pos[t5]\n",
        "            assert pos[t4] < pos[t3]\n",
        "            assert pos[t5] < pos[t2]\n",
        "            assert pos[t3] < pos[t1]\n",
        "            assert pos[t3] < pos[t2] # t3 also depends on t2\n",
        "\n",
        "            # Additional check: t2 is a dependency for both t3 and t5.\n",
        "            # In reverse topo sort, t3 and t5 must appear before t2.\n",
        "            assert pos[t3] < pos[t2]\n",
        "            assert pos[t5] < pos[t2]\n",
        "\n",
        "            # t1 is only a dependency for t3.\n",
        "            assert pos[t3] < pos[t1]\n",
        "\n",
        "            # Check if all 6 tensors are in the sorted list\n",
        "            assert len(sorted_tensors) == 6\n",
        "            assert set(sorted_tensors) == {t1, t2, t3, t4, t5, t6}\n",
        "\n",
        "# To run these tests, save the code as a Python file (e.g., `test_autograd.py`)\n",
        "# and run `pytest` from your terminal in the same directory.\n",
        "# `pip install pytest torch rustworkx` if you don't have them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "qlerSJMBZVyu"
      },
      "outputs": [],
      "source": [
        "k=TestCustomAutogradSystem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "JqLizMhYZYFt"
      },
      "outputs": [],
      "source": [
        "k.test_basic_add_scalar_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "-RzvJuk8ZcxQ"
      },
      "outputs": [],
      "source": [
        "k.test_basic_add_tensor_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "FRSjwXxXdNRr"
      },
      "outputs": [],
      "source": [
        "k.test_mixed_requires_grad_tensor_add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "NeI2AJpgdStt"
      },
      "outputs": [],
      "source": [
        "k.test_no_requires_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "VDDJgK0xd2ob"
      },
      "outputs": [],
      "source": [
        "k.test_autograd_graph_context_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khP3jZxDd6hC",
        "outputId": "4041e6ae-f87d-4254-885f-cab08ed7ca13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raised the error of cycle detected as Cycle detected in autograd graph on context exit.\n"
          ]
        }
      ],
      "source": [
        "k.test_cycle_detection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfG1rNMXiCa9",
        "outputId": "54e6b624-fbd3-46d2-e6c5-b843bb30f6a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJQ9maoLeEGk",
        "outputId": "1b9de0eb-ce2a-4572-867d-bdf6d5354ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "d <__main__.CustomTensor object at 0x78a841a447c0>\n",
            "3\n",
            "2\n",
            "<weakref at 0x78a841a47420; to 'CustomTensor' at 0x78a841a447c0>\n",
            "3\n",
            "2\n",
            "Outut_Tensor_weak_ref <weakref at 0x78a841a47420; dead>\n",
            "\n",
            "Running advanced GC test for intermediate tensors...\n"
          ]
        }
      ],
      "source": [
        "k.test_no_circular_references_non_leaf_tensors_die()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "k0bgwgYpjLow"
      },
      "outputs": [],
      "source": [
        "def test_no_circular_references_non_leaf_tensors_die(self):\n",
        "          # This test relies on the garbage collector. It's a heuristic test\n",
        "        # as Python's GC timing is not strictly deterministic.\n",
        "        # However, with weakrefs, it should work for non-leaf tensors.\n",
        "\n",
        "    print(\"\\n--- Starting GC Test: No Circular References (Part 1) ---\")\n",
        "\n",
        "    graph_ref = None\n",
        "    output_tensor_weak_ref = None\n",
        "    node_id_d = -1 # To store node_id before d is deleted\n",
        "\n",
        "    # BLOCK 1: Create graph and tensors\n",
        "    with AutogradGraph(auto_cleanup=False) as graph: # Keep graph for inspection\n",
        "        graph_ref = weakref.ref(graph)\n",
        "        a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "        b = a + 1.0 # Intermediate tensor\n",
        "        c = b + 2.0 # Intermediate tensor\n",
        "        d = c + 3.0 # Output tensor (also intermediate from graph's perspective)\n",
        "\n",
        "        # Store weak reference to 'd' BEFORE its strong reference is potentially removed\n",
        "        output_tensor_weak_ref = weakref.ref(d)\n",
        "        node_id_d = d._node_id # Store node_id while d is alive\n",
        "\n",
        "        print(f\"Initial: d object: {d}\")\n",
        "        print(f\"Initial: d._node_id: {node_id_d}\")\n",
        "        print(f\"Initial: graph.intermediate_tensors keys: {list(graph.intermediate_tensors.keys())}\")\n",
        "        # The ref count for `d` object itself will be high here because it's in `graph.intermediate_tensors`,\n",
        "        # and held by variable `d`, and by the temporary ref in `getrefcount`.\n",
        "        print(f\"Initial: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'}\")\n",
        "        assert len(graph.intermediate_tensors) == 3 # b, c, d should be in intermediate_tensors\n",
        "\n",
        "    # BLOCK 2: After exiting context manager (auto_cleanup=False)\n",
        "    print(\"\\n--- After exiting 'with' block (auto_cleanup=False) ---\")\n",
        "    # The 'graph' variable still holds a strong reference to the AutogradGraph instance.\n",
        "    # graph_ref() should return the graph object.\n",
        "    assert graph_ref() is not None, \"Graph object should still be alive.\"\n",
        "    assert len(graph_ref().intermediate_tensors) == 3, \"Intermediate tensors should still be referenced by the graph.\"\n",
        "    print(f\"After 'with' block: d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "    print(f\"After 'with' block: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref())}\")\n",
        "\n",
        "    # BLOCK 3: Remove strong reference 'd' from local scope\n",
        "    print(\"\\n--- Deleting 'd' variable ---\")\n",
        "    del d # Remove the local strong reference to the CustomTensor object.\n",
        "    gc.collect() # Force garbage collection\n",
        "\n",
        "    # Now, output_tensor_weak_ref() *still* shouldn't be None because `graph_ref().intermediate_tensors`\n",
        "    # holds the strong reference.\n",
        "    print(f\"After del d + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "    # We expect this to *not* be None yet, and to still show a refcount reflecting intermediate_tensors.\n",
        "    assert output_tensor_weak_ref() is not None, \"d should still be alive due to intermediate_tensors.\"\n",
        "    current_d_refcount_after_del_d = sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'\n",
        "    print(f\"After del d + gc.collect(): refcount of d: {current_d_refcount_after_del_d}\")\n",
        "    # Expected refcount should be 2: one from intermediate_tensors, one from getrefcount()\n",
        "    assert current_d_refcount_after_del_d == 2, f\"Expected refcount 2, got {current_d_refcount_after_del_d}\"\n",
        "\n",
        "    # BLOCK 4: Remove strong reference from intermediate_tensors\n",
        "    print(f\"\\n--- Deleting strong reference from graph.intermediate_tensors for node {node_id_d} ---\")\n",
        "    graph_ref().del_non_leaf_tensor_reference(node_id_d) # THIS IS THE CRUCIAL STEP\n",
        "    print(f\"After del_non_leaf_tensor_reference: graph.intermediate_tensors keys: {list(graph_ref().intermediate_tensors.keys())}\")\n",
        "    #gc.collect() # Force garbage collection again\n",
        "\n",
        "    # Now, with the last strong reference gone, 'd' should be garbage collected.\n",
        "    print(f\"After del_non_leaf_tensor_reference + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "    # This is where your original assertion was. It *should* pass now.\n",
        "    assert output_tensor_weak_ref() is None, \"Output tensor (non-leaf) should be garbage collected after its strong reference is deleted from intermediate_tensors.\"\n",
        "    print(\"Assertion Passed: Output tensor (d) was garbage collected.\")\n",
        "\n",
        "    # BLOCK 5: Verify other intermediate tensors are collected when graph is cleared\n",
        "    print(\"\\n--- Starting GC Test: All Intermediate Tensors ---\")\n",
        "    intermediate_tensors_wrefs = []\n",
        "    # Create a new graph and new tensors to avoid interference from previous block\n",
        "    with AutogradGraph(auto_cleanup=False) as graph_new:\n",
        "        a_new = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph_new, is_leaf=True)\n",
        "        b_new = a_new + 1.0 # Intermediate\n",
        "        c_new = b_new + 2.0 # Intermediate\n",
        "        d_new = c_new + 3.0 # Intermediate (output of a chain)\n",
        "\n",
        "        # Store weak references to the intermediate tensors\n",
        "        intermediate_tensors_wrefs.append(weakref.ref(b_new))\n",
        "        intermediate_tensors_wrefs.append(weakref.ref(c_new))\n",
        "        intermediate_tensors_wrefs.append(weakref.ref(d_new))\n",
        "\n",
        "        # Verify they are initially alive\n",
        "        assert all(wref() is not None for wref in intermediate_tensors_wrefs)\n",
        "        assert len(graph_new.intermediate_tensors) == 3\n",
        "\n",
        "    print(f\"After 'with' block (new graph): graph_new object: {graph_new}\")\n",
        "    assert graph_new is not None, \"New graph object should still be alive after 'with' block.\"\n",
        "    assert len(graph_new.intermediate_tensors) == 3, \"New graph intermediate_tensors should still hold refs.\"\n",
        "\n",
        "    # Manually clear the intermediate_tensors dictionary and remove graph reference\n",
        "    print(\"\\n--- Manually clearing graph.intermediate_tensors and deleting graph ---\")\n",
        "    graph_new.intermediate_tensors.clear()\n",
        "    del graph_new # Remove the strong reference to the graph itself\n",
        "    del b_new , c_new , d_new # deleting the local variable strong references\n",
        "    #gc.collect()\n",
        "\n",
        "    # Now, all non-leaf tensors should be garbage collected\n",
        "    for i, wref in enumerate(intermediate_tensors_wrefs):\n",
        "        print(f\"Intermediate tensor {i} (via weakref): {wref()}\")\n",
        "        assert wref() is None, f\"Intermediate tensor {i} should be garbage collected after graph context and intermediate_tensors are cleared.\"\n",
        "    print(\"Assertion Passed: All intermediate tensors were garbage collected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8MD9T3jWsG",
        "outputId": "ff13f91f-728d-4181-9e7f-6e8e3db70690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting GC Test: No Circular References (Part 1) ---\n",
            "Initial: d object: <__main__.CustomTensor object at 0x78a841a2f4c0>\n",
            "Initial: d._node_id: 3\n",
            "Initial: graph.intermediate_tensors keys: [1, 2, 3]\n",
            "Initial: refcount of d (via output_tensor_weak_ref.test_ref): 3\n",
            "\n",
            "--- After exiting 'with' block (auto_cleanup=False) ---\n",
            "After 'with' block: d object (via weakref): <__main__.CustomTensor object at 0x78a841a2f4c0>\n",
            "After 'with' block: refcount of d (via output_tensor_weak_ref.test_ref): 3\n",
            "\n",
            "--- Deleting 'd' variable ---\n",
            "After del d + gc.collect(): d object (via weakref): <__main__.CustomTensor object at 0x78a841a2f4c0>\n",
            "After del d + gc.collect(): refcount of d: 2\n",
            "\n",
            "--- Deleting strong reference from graph.intermediate_tensors for node 3 ---\n",
            "After del_non_leaf_tensor_reference: graph.intermediate_tensors keys: [1, 2]\n",
            "After del_non_leaf_tensor_reference + gc.collect(): d object (via weakref): None\n",
            "Assertion Passed: Output tensor (d) was garbage collected.\n",
            "\n",
            "--- Starting GC Test: All Intermediate Tensors ---\n",
            "After 'with' block (new graph): graph_new object: CustomAutogradGraph(nodes=4, edges=3)\n",
            "\n",
            "--- Manually clearing graph.intermediate_tensors and deleting graph ---\n",
            "Intermediate tensor 0 (via weakref): None\n",
            "Intermediate tensor 1 (via weakref): None\n",
            "Intermediate tensor 2 (via weakref): None\n",
            "Assertion Passed: All intermediate tensors were garbage collected.\n"
          ]
        }
      ],
      "source": [
        "test_no_circular_references_non_leaf_tensors_die()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# build 9 july"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w638ekDnjXKm"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'base (Python 3.13.2)' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx\n",
        "import pytest\n",
        "\n",
        "# Original code (assuming it's in a file named 'autograd_system.py' or similar)\n",
        "# For the purpose of this test code, I'll include it directly.\n",
        "\n",
        "# class Operations:\n",
        "#     @torch.jit.script\n",
        "#     def add_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "#         return tensor + scalar\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def add_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "#         return tensor1 + tensor2\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def mul_tensor_and_scaler(tensor: torch.Tensor, scaler: float) -> torch.Tensor:\n",
        "#         return tensor * scaler\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def mul_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "#         return tensor1 * tensor2\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def sub_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "#         return tensor - scalar\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def sub_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "#         return tensor1 - tensor2\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def div_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "#         return tensor / scalar\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def pow_tensor_and_scalar(tensor: torch.Tensor, scalar: float) -> torch.Tensor:\n",
        "#         return tensor.pow(scalar)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def exp_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.exp(tensor)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def log_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.log(tensor)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def sin_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.sin(tensor)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def cos_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.cos(tensor)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def dot_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.dot(tensor1, tensor2)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def apply_binary_mask(tensor: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "#         return tensor * mask\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def sqrt_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.sqrt(tensor)\n",
        "\n",
        "#     @torch.jit.script\n",
        "#     def matmul_tensor_and_tensor(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor:\n",
        "#         return torch.matmul(tensor1, tensor2)\n",
        "\n",
        "#     def einsum(equation: str, *operands) -> torch.Tensor:\n",
        "#         # torch.jit.script does not support variable arguments or string arguments well,\n",
        "#         # so einsum cannot be scripted. Leave as a static method.\n",
        "#         return torch.einsum(equation, *operands)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install rustworkx\n",
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx\n",
        "import pytest\n",
        "\n",
        "class AutogradGraph:\n",
        "    __slots__ = ('graph', 'intermediate_tensors', '_check_cycles', '_auto_cleanup', '_latest_node_id')\n",
        "    def __init__(self, check_for_cycles=True, auto_cleanup=True):\n",
        "\n",
        "        self.graph = rx.PyDiGraph()\n",
        "        self.intermediate_tensors = {}\n",
        "        self._check_cycles = check_for_cycles\n",
        "        self._auto_cleanup = auto_cleanup\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._check_cycles and self.check_cycle():\n",
        "            raise RuntimeError(\"Cycle detected in autograd graph on context exit.\")\n",
        "        if self._auto_cleanup:\n",
        "            self.intermediate_tensors.clear()\n",
        "            self.graph.clear()\n",
        "\n",
        "    def add_tensor_graph(self, tensor, is_leaf):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor with requires_grad=False cannot be added to the graph.\")\n",
        "\n",
        "        ref = tensor if is_leaf else weakref.proxy(tensor)\n",
        "        tensor_index = self.graph.add_node(ref)\n",
        "        tensor._node_id = tensor_index\n",
        "\n",
        "    def add_non_leaf_tensor_reference(self, tensor):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor must require grad.\")\n",
        "\n",
        "        if tensor._node_id in self.intermediate_tensors:\n",
        "            raise ValueError(\"Tensor reference already exists in intermediate tensors.\")\n",
        "\n",
        "        self.intermediate_tensors[tensor._node_id] = tensor\n",
        "\n",
        "    def add_edge(self, node_from, node_to, weight=None):\n",
        "        if not all(isinstance(n, int) for n in (node_from, node_to)):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "        if not self.graph.has_node(node_from) or not self.graph.has_node(node_to):\n",
        "            raise ValueError(\"Nodes must exist before adding edge.\")\n",
        "        self.graph.add_edge(node_from, node_to, weight)\n",
        "\n",
        "    def check_cycle(self):\n",
        "        return not rx.is_directed_acyclic_graph(self.graph)\n",
        "\n",
        "    def reverse_toposort(self):\n",
        "        return [self.graph[n] for n in reversed(rx.topological_sort(self.graph))]\n",
        "\n",
        "    def reverse_toposort_from_tensor(self, tensor_index):\n",
        "        graph=self.graph\n",
        "        predecessors = list(rx.ancestors(graph, tensor_index))\n",
        "        predecessors.append(tensor_index)\n",
        "        sub_graph = graph.subgraph(predecessors)\n",
        "        return [sub_graph[i] for i in reversed(rx.topological_sort(sub_graph))]\n",
        "    \n",
        "    # def alternative_reverse_toposort_from_tensor(self, tensor_index):\n",
        "    #     graph = self.graph\n",
        "    #     relevant_nodes = rx.ancestors(graph, tensor_index)\n",
        "    #     relevant_nodes.add(tensor_index)\n",
        "    #     full_topo = rx.topological_sort(graph)\n",
        "    #     relevant_topo = [graph[_node_id] for _node_id in reversed(full_topo) if _node_id in relevant_nodes]\n",
        "    #     return relevant_topo\n",
        "        \n",
        "    def delete_node(self, node_index):\n",
        "        if not isinstance(node_index, int):\n",
        "            raise TypeError(\"Node index must be an integer.\")\n",
        "        if not self.graph.has_node(node_index):\n",
        "            raise ValueError(\"Node does not exist.\")\n",
        "        self.graph.remove_node(node_index)\n",
        "\n",
        "    def delete_edge(self, node_from, node_to):\n",
        "        if not self.graph.has_edge(node_from, node_to):\n",
        "            raise ValueError(\"Edge does not exist.\")\n",
        "        self.graph.remove_edge(node_from, node_to)\n",
        "\n",
        "    def del_non_leaf_tensor_reference(self, tensor_node_id):\n",
        "        self.intermediate_tensors.pop(tensor_node_id, None)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CustomAutogradGraph(nodes={self.graph.num_nodes()}, edges={self.graph.num_edges()})\"\n",
        "\n",
        "class CustomTensor:\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph', '__weakref__')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data  # Don't rewrap\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return\n",
        "\n",
        "        self.tensor = data if due_to_operation else torch.as_tensor(data, dtype=dtype, device=device)\n",
        "        self.tensor.requires_grad_(False)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "\n",
        "        if _custom_requires_grad:\n",
        "            self._init_graph(graph, is_leaf)\n",
        "\n",
        "    def _init_graph(self, graph, is_leaf):\n",
        "        if graph is None:\n",
        "            raise ValueError(\"Graph must be provided if requires_grad is True.\")\n",
        "        if is_leaf:\n",
        "          self.graph = weakref.proxy(graph)\n",
        "        else:\n",
        "          self.graph = graph\n",
        "        graph.add_tensor_graph(self, is_leaf=is_leaf)\n",
        "        if not is_leaf:\n",
        "            graph.add_non_leaf_tensor_reference(self)\n",
        "\n",
        "    def _zero_grad(self):\n",
        "        self.tensor.grad = torch.zeros_like(self.tensor)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._add_scalar(other)#, op=torch.add)#Operations.add_tensor_and_scalar)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._add_tensor(other)#, op=torch.add)#Operations.add_tensor_and_tensor)\n",
        "        return NotImplemented\n",
        "\n",
        "    def _add_scalar(self, scalar):\n",
        "        result_tensor = torch.add(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            # print(f\"Backward for scalar add: result_grad={result.tensor.grad}, self_grad_before={self_ref.tensor.grad}\") # Debugging\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "            # print(f\"Backward for scalar add: self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _add_tensor(self, other):\n",
        "        result_tensor = torch.add(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        # Graph selection logic - assuming operations happen within a single graph context\n",
        "        graph = None\n",
        "        if self._custom_requires_grad:\n",
        "            graph = self.graph\n",
        "        elif other._custom_requires_grad:\n",
        "            graph = other.graph\n",
        "        else:\n",
        "            # This case should ideally not be reached if requires_grad is True\n",
        "            # and at least one operand has requires_grad\n",
        "            pass # Or raise an error if graph is truly missing\n",
        "\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            # print(f\"Backward for tensor add: result_grad={result.tensor.grad}\") # Debugging\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  other_grad_after={other_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def __mul__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._mul_scalar(other)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._mul_tensor(other)\n",
        "        return NotImplemented\n",
        "\n",
        "    def _mul_scalar(self, scalar):\n",
        "        result_tensor = torch.mul(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad * scalar)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _mul_tensor(self, other):\n",
        "        result_tensor = torch.mul(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * other_ref.tensor)\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._sub_scalar(other)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._sub_tensor(other)\n",
        "        return NotImplemented\n",
        "\n",
        "    def _sub_scalar(self, scalar):\n",
        "        result_tensor = torch.sub(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _sub_tensor(self, other):\n",
        "        result_tensor = torch.sub(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.sub_(result_ref.tensor.grad)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    \n",
        "    def __truediv__(self, scalar):\n",
        "        return self._div_scalar(scalar)\n",
        "\n",
        "    def _div_scalar(self, scalar):\n",
        "        result_tensor = torch.div(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad / scalar)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "\n",
        "    def pow(self, scalar):\n",
        "        result_tensor = torch.pow(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            grad_contrib = scalar * self_ref.tensor.pow(scalar - 1)\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad * grad_contrib)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    \n",
        "    def exp(self):\n",
        "        out = torch.exp(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, out_tensor: grad * out_tensor)\n",
        "\n",
        "    def log(self):\n",
        "        out = torch.log(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: grad / input_tensor)\n",
        "\n",
        "    def sin(self):\n",
        "        out = torch.sin(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: grad * torch.cos(input_tensor))\n",
        "\n",
        "    def cos(self):\n",
        "        out = torch.cos(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: -grad * torch.sin(input_tensor))\n",
        "\n",
        "    def sqrt(self):\n",
        "        out = torch.sqrt(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, out_tensor: grad * 0.5 / out_tensor)\n",
        "\n",
        "    def _unary_op(self, result_tensor, backward_fn):\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(backward_fn(result_ref.tensor.grad, self_ref.tensor))\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def matmul(self, other):\n",
        "        result_tensor = torch.matmul(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(torch.matmul(result_ref.tensor.grad, other_ref.tensor.t()))\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(torch.matmul(self_ref.tensor.t(), result_ref.tensor.grad))\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def apply_mask(self, mask):\n",
        "        result_tensor = self.tensor * mask.tensor\n",
        "        requires_grad = self._custom_requires_grad or mask._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else mask.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        mask_ref = weakref.proxy(mask)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if mask._custom_requires_grad:\n",
        "            graph.add_edge(mask._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * mask_ref.tensor)\n",
        "            if mask._custom_requires_grad:\n",
        "                if mask_ref.tensor.grad is None:\n",
        "                    mask_ref._zero_grad()\n",
        "                mask_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    \n",
        "    def dot(self, other):\n",
        "        result_tensor = torch.dot(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * other_ref.tensor)\n",
        "            if other._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def backward(self,weightage_tensor=1):\n",
        "        if not self._custom_requires_grad:\n",
        "            raise RuntimeError(\"Output tensor does not require grad.\")\n",
        "        if self.graph is None:\n",
        "            raise RuntimeError(\"Output tensor is not part of a graph.\")\n",
        "        graph = self.graph\n",
        "\n",
        "        # Initialize gradient for the output tensor\n",
        "        if isinstance(weightage_tensor,numbers.Number):\n",
        "            self.tensor.grad = torch.full_like(self.tensor, fill_value=weightage_tensor)\n",
        "        elif isinstance(weightage_tensor,torch.Tensor):\n",
        "            self.tensor.grad = weightage_tensor.clone() # we don't want to modify the original tensor data\n",
        "\n",
        "        # Perform backward pass using topological sort\n",
        "\n",
        "        nodes_to_process = graph.reverse_toposort_from_tensor(self._node_id)\n",
        "\n",
        "        # Create a strong reference to intermediate tensors needed for backward pass\n",
        "        # This simulates how a real autograd engine would keep track of them\n",
        "        # The graph context's intermediate_tensors dict already serves this purpose.\n",
        "\n",
        "        for tensor_node in nodes_to_process:\n",
        "            # Check if the weak proxy is still valid (tensor is alive)\n",
        "            if isinstance(tensor_node, weakref.ProxyTypes) and tensor_node.__slots__ is None:\n",
        "                # print(f\"Skipping dead proxy: {tensor_node}\") # Debugging\n",
        "                continue # Skip if the weak reference is dead\n",
        "\n",
        "            if tensor_node.tensor.grad is None and tensor_node is not self.tensor:\n",
        "                # This can happen if a tensor is part of the graph but its grad hasn't been set yet\n",
        "                # and it's not the root of the backward call. This typically means it's a leaf\n",
        "                # that wasn't used to compute the output or an intermediate that accumulated no grad.\n",
        "                # For simplicity in this test, we assume grads propagate.\n",
        "                # print(f\"Warning: Tensor node {tensor_node._node_id} has no grad before _backward call.\")\n",
        "                pass # A no-op for now. In a real system, you might want to handle this.\n",
        "\n",
        "            # Ensure that non-leaf tensors are still alive when their _backward is called\n",
        "            # The `intermediate_tensors` in `AutogradGraph` should keep them alive.\n",
        "            tensor_node._backward()\n",
        "\n",
        "        # Clean up intermediate tensors references after backward pass\n",
        "        # This would typically be handled by the graph context's exit, but\n",
        "        # if `_auto_cleanup` is False, you might need manual cleanup.\n",
        "        # Here, for testing GC, we'll let the context manager handle it.\n",
        "\n",
        "        \n",
        "\n",
        "    def __del__(self):\n",
        "        print(\"Garbage Collector has decided that reference counts are zero so Goodbye!!\")\n",
        "\n"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test AutoGRAD graph and weak ref as well as grads\n",
        "\"\"\"\n",
        "a=t\n",
        "b=t\n",
        "c= a+b\n",
        "d= a/c +c +b\n",
        "e=(c+1)*d + a*c*b\n",
        "f=e+c+a\n",
        "creating graph\n",
        "a ---->   a------>                                        a------>                            a------>\n",
        "                                                                  *                                   +\n",
        "                                                                                                        f\n",
        "                  / t1-->\n",
        "                        + t2-->\n",
        "                              + d----> d-------->\n",
        "                                                * t4------------------------------->\n",
        "                                                                  t5------>\n",
        "        + c ---->   c--->         c--->                   c----->                    c------>\n",
        "                                                                                            + t7 ----->\n",
        "                                        + t3---->                                  + e------>\n",
        "                                  1--->                                    t6------>\n",
        "                                                                          *\n",
        "b ---->   b-------------------->                                   b------>\n",
        "\"\"\"\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Test Code ---\n",
        "\n",
        "def run_backward(output_tensor: CustomTensor):\n",
        "    \"\"\"\n",
        "    Simulates the backward pass for the custom autograd system.\n",
        "    This function needs to be explicitly defined as it's not part of the original classes.\n",
        "    \"\"\"\n",
        "    if not output_tensor._custom_requires_grad:\n",
        "        raise RuntimeError(\"Output tensor does not require grad.\")\n",
        "    if output_tensor.graph is None:\n",
        "        raise RuntimeError(\"Output tensor is not part of a graph.\")\n",
        "\n",
        "    # Initialize gradient for the output tensor\n",
        "    output_tensor.tensor.grad = torch.ones_like(output_tensor.tensor)\n",
        "\n",
        "    # Perform backward pass using topological sort\n",
        "    nodes_to_process = output_tensor.graph.reverse_toposort()\n",
        "\n",
        "    # Create a strong reference to intermediate tensors needed for backward pass\n",
        "    # This simulates how a real autograd engine would keep track of them\n",
        "    # The graph context's intermediate_tensors dict already serves this purpose.\n",
        "\n",
        "    for tensor_node in nodes_to_process:\n",
        "        # Check if the weak proxy is still valid (tensor is alive)\n",
        "        if isinstance(tensor_node, weakref.ProxyTypes) and tensor_node.__slots__ is None:\n",
        "            # print(f\"Skipping dead proxy: {tensor_node}\") # Debugging\n",
        "            continue # Skip if the weak reference is dead\n",
        "\n",
        "        if tensor_node.tensor.grad is None and tensor_node is not output_tensor:\n",
        "            # This can happen if a tensor is part of the graph but its grad hasn't been set yet\n",
        "            # and it's not the root of the backward call. This typically means it's a leaf\n",
        "            # that wasn't used to compute the output or an intermediate that accumulated no grad.\n",
        "            # For simplicity in this test, we assume grads propagate.\n",
        "            # print(f\"Warning: Tensor node {tensor_node._node_id} has no grad before _backward call.\")\n",
        "            pass # A no-op for now. In a real system, you might want to handle this.\n",
        "\n",
        "        # Ensure that non-leaf tensors are still alive when their _backward is called\n",
        "        # The `intermediate_tensors` in `AutogradGraph` should keep them alive.\n",
        "        tensor_node._backward()\n",
        "\n",
        "    # Clean up intermediate tensors references after backward pass\n",
        "    # This would typically be handled by the graph context's exit, but\n",
        "    # if `_auto_cleanup` is False, you might need manual cleanup.\n",
        "    # Here, for testing GC, we'll let the context manager handle it.\n",
        "\n",
        "\n",
        "class TestCustomAutogradSystem:\n",
        "\n",
        "    def test_basic_add_scalar_grad(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = a + 5.0 # (a + 5)\n",
        "            c = b + 10.0 # (a + 5 + 10)\n",
        "\n",
        "            # Manually run backward pass\n",
        "            run_backward(c)\n",
        "\n",
        "            # Expected gradients:\n",
        "            # dC/dA = 1.0 (for each element)\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert b.tensor.grad is not None\n",
        "            assert torch.allclose(b.tensor.grad, torch.tensor([1.0, 1.0])) # dC/dB = 1.0\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 3\n",
        "            assert graph.graph.num_edges() == 2\n",
        "            assert graph.graph.has_edge(a._node_id, b._node_id)\n",
        "            assert graph.graph.has_edge(b._node_id, c._node_id)\n",
        "            assert graph.check_cycle() is True\n",
        "\n",
        "    def test_basic_add_tensor_grad(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([1.0, 2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            c = a + b # (a + b)\n",
        "            d = c + 5.0 # (a + b + 5)\n",
        "\n",
        "            run_backward(d)\n",
        "\n",
        "            # Expected gradients:\n",
        "            # dD/dA = 1.0\n",
        "            # dD/dB = 1.0\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert torch.allclose(b.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 4\n",
        "            assert graph.graph.num_edges() == 3\n",
        "            assert graph.graph.has_edge(a._node_id, c._node_id)\n",
        "            assert graph.graph.has_edge(b._node_id, c._node_id)\n",
        "            assert graph.graph.has_edge(c._node_id, d._node_id)\n",
        "            assert graph.check_cycle() is True\n",
        "\n",
        "    def test_mixed_requires_grad_tensor_add(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            a = CustomTensor(torch.tensor([2.0, 3.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([1.0, 2.0]), _custom_requires_grad=False) # Does not require grad\n",
        "            c = a + b # c should require grad, b's grad should be None\n",
        "\n",
        "            run_backward(c)\n",
        "\n",
        "            assert torch.allclose(a.tensor.grad, torch.tensor([1.0, 1.0]))\n",
        "            assert b.tensor.grad is None # b should not have a grad\n",
        "            assert c._custom_requires_grad is True\n",
        "\n",
        "            # Verify graph structure\n",
        "            assert graph.graph.num_nodes() == 2 # Only a and c in the graph\n",
        "            assert graph.graph.num_edges() == 1\n",
        "            assert graph.graph.has_node(a._node_id)\n",
        "            assert graph.graph.has_node(c._node_id)\n",
        "            assert graph.graph.has_edge(a._node_id, c._node_id)\n",
        "            #assert not graph.graph.has_node(b._node_id) # b should not be in graph\n",
        "\n",
        "    def test_no_requires_grad(self):\n",
        "        with AutogradGraph() as graph: # Graph created, but no tensors with requires_grad=True added\n",
        "            a = CustomTensor(torch.tensor([1.0]))\n",
        "            b = CustomTensor(torch.tensor([2.0]))\n",
        "            c = a + b\n",
        "            d = c + 3.0\n",
        "\n",
        "            assert not a._custom_requires_grad\n",
        "            assert not b._custom_requires_grad\n",
        "            assert not c._custom_requires_grad\n",
        "            assert not d._custom_requires_grad\n",
        "            assert graph.graph.num_nodes() == 0 # Graph should remain empty\n",
        "            assert graph.graph.num_edges() == 0\n",
        "\n",
        "            with pytest.raises(RuntimeError, match=\"Output tensor does not require grad.\"):\n",
        "                run_backward(d)\n",
        "\n",
        "    def test_autograd_graph_context_manager(self):\n",
        "        graph = None\n",
        "        with AutogradGraph(check_for_cycles=True, auto_cleanup=True) as g:\n",
        "            graph = g\n",
        "            a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = a + 1.0\n",
        "            assert graph.graph.num_nodes() == 2\n",
        "            assert graph.graph.num_edges() == 1\n",
        "            assert len(graph.intermediate_tensors) == 1 # b should be in intermediate_tensors\n",
        "\n",
        "        # After exiting the context, graph should be empty\n",
        "        assert graph.graph.num_nodes() == 0\n",
        "        assert graph.graph.num_edges() == 0\n",
        "        assert len(graph.intermediate_tensors) == 0\n",
        "\n",
        "    def test_cycle_detection(self):\n",
        "      try:\n",
        "        with AutogradGraph(check_for_cycles=True, auto_cleanup=False) as graph: # auto_cleanup=False to inspect after error\n",
        "            a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            b = CustomTensor(torch.tensor([2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "\n",
        "            # Manually create a cycle (a -> b -> a)\n",
        "            graph.add_edge(a._node_id, b._node_id)\n",
        "            graph.add_edge(b._node_id, a._node_id)\n",
        "      except RuntimeError as e:\n",
        "        print(f\"Raised the error of cycle detected as {e}\")\n",
        "            # with pytest.raises(RuntimeError, match=\"Cycle detected in autograd graph on context exit.\"):\n",
        "            #     pass # The __exit__ method will be called here\n",
        "\n",
        "    def test_no_circular_references_non_leaf_tensors_die(self):\n",
        "          # This test relies on the garbage collector. It's a heuristic test\n",
        "        # as Python's GC timing is not strictly deterministic.\n",
        "        # However, with weakrefs, it should work for non-leaf tensors.\n",
        "\n",
        "      print(\"\\n--- Starting GC Test: No Circular References (Part 1) ---\")\n",
        "\n",
        "      graph_ref = None\n",
        "      output_tensor_weak_ref = None\n",
        "      node_id_d = -1 # To store node_id before d is deleted\n",
        "\n",
        "      # BLOCK 1: Create graph and tensors\n",
        "      with AutogradGraph(auto_cleanup=False) as graph: # Keep graph for inspection\n",
        "          graph_ref = weakref.ref(graph)\n",
        "          a = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "          b = a + 1.0 # Intermediate tensor\n",
        "          c = b + 2.0 # Intermediate tensor\n",
        "          d = c + 3.0 # Output tensor (also intermediate from graph's perspective)\n",
        "\n",
        "          # Store weak reference to 'd' BEFORE its strong reference is potentially removed\n",
        "          output_tensor_weak_ref = weakref.ref(d)\n",
        "          node_id_d = d._node_id # Store node_id while d is alive\n",
        "\n",
        "          print(f\"Initial: d object: {d}\")\n",
        "          print(f\"Initial: d._node_id: {node_id_d}\")\n",
        "          print(f\"Initial: graph.intermediate_tensors keys: {list(graph.intermediate_tensors.keys())}\")\n",
        "          # The ref count for `d` object itself will be high here because it's in `graph.intermediate_tensors`,\n",
        "          # and held by variable `d`, and by the temporary ref in `getrefcount`.\n",
        "          print(f\"Initial: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'}\")\n",
        "          assert len(graph.intermediate_tensors) == 3 # b, c, d should be in intermediate_tensors\n",
        "\n",
        "      # BLOCK 2: After exiting context manager (auto_cleanup=False)\n",
        "      print(\"\\n--- After exiting 'with' block (auto_cleanup=False) ---\")\n",
        "      # The 'graph' variable still holds a strong reference to the AutogradGraph instance.\n",
        "      # graph_ref() should return the graph object.\n",
        "      assert graph_ref() is not None, \"Graph object should still be alive.\"\n",
        "      assert len(graph_ref().intermediate_tensors) == 3, \"Intermediate tensors should still be referenced by the graph.\"\n",
        "      print(f\"After 'with' block: d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      print(f\"After 'with' block: refcount of d (via output_tensor_weak_ref.test_ref): {sys.getrefcount(output_tensor_weak_ref())}\")\n",
        "\n",
        "      # BLOCK 3: Remove strong reference 'd' from local scope\n",
        "      print(\"\\n--- Deleting 'd' variable ---\")\n",
        "      del d # Remove the local strong reference to the CustomTensor object.\n",
        "      gc.collect() # Force garbage collection\n",
        "\n",
        "      # Now, output_tensor_weak_ref() *still* shouldn't be None because `graph_ref().intermediate_tensors`\n",
        "      # holds the strong reference.\n",
        "      print(f\"After del d + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      # We expect this to *not* be None yet, and to still show a refcount reflecting intermediate_tensors.\n",
        "      assert output_tensor_weak_ref() is not None, \"d should still be alive due to intermediate_tensors.\"\n",
        "      current_d_refcount_after_del_d = sys.getrefcount(output_tensor_weak_ref()) if output_tensor_weak_ref() else 'N/A'\n",
        "      print(f\"After del d + gc.collect(): refcount of d: {current_d_refcount_after_del_d}\")\n",
        "      # Expected refcount should be 2: one from intermediate_tensors, one from getrefcount()\n",
        "      assert current_d_refcount_after_del_d == 2, f\"Expected refcount 2, got {current_d_refcount_after_del_d}\"\n",
        "\n",
        "      # BLOCK 4: Remove strong reference from intermediate_tensors\n",
        "      print(f\"\\n--- Deleting strong reference from graph.intermediate_tensors for node {node_id_d} ---\")\n",
        "      graph_ref().del_non_leaf_tensor_reference(node_id_d) # THIS IS THE CRUCIAL STEP\n",
        "      print(f\"After del_non_leaf_tensor_reference: graph.intermediate_tensors keys: {list(graph_ref().intermediate_tensors.keys())}\")\n",
        "      #gc.collect() # Force garbage collection again\n",
        "\n",
        "      # Now, with the last strong reference gone, 'd' should be garbage collected.\n",
        "      print(f\"After del_non_leaf_tensor_reference + gc.collect(): d object (via weakref): {output_tensor_weak_ref()}\")\n",
        "      # This is where your original assertion was. It *should* pass now.\n",
        "      assert output_tensor_weak_ref() is None, \"Output tensor (non-leaf) should be garbage collected after its strong reference is deleted from intermediate_tensors.\"\n",
        "      print(\"Assertion Passed: Output tensor (d) was garbage collected.\")\n",
        "\n",
        "      # BLOCK 5: Verify other intermediate tensors are collected when graph is cleared\n",
        "      print(\"\\n--- Starting GC Test: All Intermediate Tensors ---\")\n",
        "      intermediate_tensors_wrefs = []\n",
        "      # Create a new graph and new tensors to avoid interference from previous block\n",
        "      with AutogradGraph(auto_cleanup=False) as graph_new:\n",
        "          a_new = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph_new, is_leaf=True)\n",
        "          b_new = a_new + 1.0 # Intermediate\n",
        "          c_new = b_new + 2.0 # Intermediate\n",
        "          d_new = c_new + 3.0 # Intermediate (output of a chain)\n",
        "\n",
        "          # Store weak references to the intermediate tensors\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(b_new))\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(c_new))\n",
        "          intermediate_tensors_wrefs.append(weakref.ref(d_new))\n",
        "\n",
        "          # Verify they are initially alive\n",
        "          assert all(wref() is not None for wref in intermediate_tensors_wrefs)\n",
        "          assert len(graph_new.intermediate_tensors) == 3\n",
        "\n",
        "      print(f\"After 'with' block (new graph): graph_new object: {graph_new}\")\n",
        "      assert graph_new is not None, \"New graph object should still be alive after 'with' block.\"\n",
        "      assert len(graph_new.intermediate_tensors) == 3, \"New graph intermediate_tensors should still hold refs.\"\n",
        "\n",
        "      # Manually clear the intermediate_tensors dictionary and remove graph reference\n",
        "      print(\"\\n--- Manually clearing graph.intermediate_tensors and deleting graph ---\")\n",
        "      graph_new.intermediate_tensors.clear()\n",
        "      del graph_new # Remove the strong reference to the graph itself\n",
        "      del b_new , c_new , d_new # deleting the local variable strong references\n",
        "      #gc.collect()\n",
        "\n",
        "      # Now, all non-leaf tensors should be garbage collected\n",
        "      for i, wref in enumerate(intermediate_tensors_wrefs):\n",
        "          print(f\"Intermediate tensor {i} (via weakref): {wref()}\")\n",
        "          assert wref() is None, f\"Intermediate tensor {i} should be garbage collected after graph context and intermediate_tensors are cleared.\"\n",
        "      print(\"Assertion Passed: All intermediate tensors were garbage collected.\")\n",
        "\n",
        "    def test_topological_sort_order(self):\n",
        "        with AutogradGraph() as graph:\n",
        "            t1 = CustomTensor(torch.tensor([1.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            t2 = CustomTensor(torch.tensor([2.0]), _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            t3 = t1 + t2\n",
        "            t4 = t3 + 5.0\n",
        "            t5 = t2 + 10.0 # Another branch\n",
        "            t6 = t4 + t5\n",
        "\n",
        "            # The topological sort should produce an order where dependencies come before their dependents.\n",
        "            # Reversed topological sort should produce an order where outputs come before their inputs.\n",
        "            # Example expected order: t6, t4, t5, t3, t2, t1 (or variations respecting dependencies)\n",
        "            sorted_tensors = graph.reverse_toposort()\n",
        "\n",
        "            # Check if dependencies are respected in reverse order\n",
        "            # If A -> B, then B should appear before A in reverse topological sort.\n",
        "            # t6 depends on t4, t5. So t6 should be before t4 and t5.\n",
        "            # t4 depends on t3. So t4 should be before t3.\n",
        "            # t5 depends on t2. So t5 should be before t2.\n",
        "            # t3 depends on t1, t2. So t3 should be before t1 and t2.\n",
        "\n",
        "            # Simple check: The first element should be t6 (the ultimate output).\n",
        "            assert sorted_tensors[0] is t6\n",
        "\n",
        "            # Check positions:\n",
        "            pos = {t: i for i, t in enumerate(sorted_tensors)}\n",
        "\n",
        "            assert pos[t6] < pos[t4]\n",
        "            assert pos[t6] < pos[t5]\n",
        "            assert pos[t4] < pos[t3]\n",
        "            assert pos[t5] < pos[t2]\n",
        "            assert pos[t3] < pos[t1]\n",
        "            assert pos[t3] < pos[t2] # t3 also depends on t2\n",
        "\n",
        "            # Additional check: t2 is a dependency for both t3 and t5.\n",
        "            # In reverse topo sort, t3 and t5 must appear before t2.\n",
        "            assert pos[t3] < pos[t2]\n",
        "            assert pos[t5] < pos[t2]\n",
        "\n",
        "            # t1 is only a dependency for t3.\n",
        "            assert pos[t3] < pos[t1]\n",
        "\n",
        "            # Check if all 6 tensors are in the sorted list\n",
        "            assert len(sorted_tensors) == 6\n",
        "            assert set(sorted_tensors) == {t1, t2, t3, t4, t5, t6}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import numbers\n",
        "import weakref\n",
        "import rustworkx as rx\n",
        "from typing import Optional, Any\n",
        "\n",
        "\n",
        "class AutogradTester:\n",
        "    \"\"\"Test suite to verify custom autograd against PyTorch's autograd\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.passed_tests = 0\n",
        "        self.failed_tests = 0\n",
        "        self.tolerance = 1e-6\n",
        "    \n",
        "    def assert_tensors_close(self, custom_tensor, pytorch_tensor, test_name, check_grad=True):\n",
        "        \"\"\"Compare custom tensor with PyTorch tensor\"\"\"\n",
        "        try:\n",
        "            # Check values\n",
        "            np.testing.assert_allclose(\n",
        "                custom_tensor.tensor.detach().numpy(),\n",
        "                pytorch_tensor.detach().numpy(),\n",
        "                rtol=self.tolerance,\n",
        "                atol=self.tolerance\n",
        "            )\n",
        "            \n",
        "            # Check gradients if requested\n",
        "            if check_grad and pytorch_tensor.grad is not None:\n",
        "                if custom_tensor.tensor.grad is None:\n",
        "                    raise AssertionError(f\"Custom tensor has no gradient in {test_name}\")\n",
        "                \n",
        "                np.testing.assert_allclose(\n",
        "                    custom_tensor.tensor.grad.detach().numpy(),\n",
        "                    pytorch_tensor.grad.detach().numpy(),\n",
        "                    rtol=self.tolerance,\n",
        "                    atol=self.tolerance\n",
        "                )\n",
        "            \n",
        "            print(f\"✓ {test_name}\")\n",
        "            self.passed_tests += 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"✗ {test_name}: {str(e)}\")\n",
        "            self.failed_tests += 1\n",
        "    \n",
        "    def test_basic_operations(self):\n",
        "        \"\"\"Test basic arithmetic operations\"\"\"\n",
        "        print(\"\\n=== Testing Basic Operations ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test scalar addition\n",
        "            x_custom = CustomTensor([2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom + 5.0\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = x_pytorch + 5.0\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Scalar Addition\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Scalar Addition Result\", check_grad=False)\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test tensor addition\n",
        "            x_custom = CustomTensor([1.0, 2.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([3.0, 4.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            z_custom = x_custom + y_custom\n",
        "            z_custom.tensor.backward(torch.ones_like(z_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "            z_pytorch = x_pytorch + y_pytorch\n",
        "            z_pytorch.backward(torch.ones_like(z_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Tensor Addition - x\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Tensor Addition - y\")\n",
        "    \n",
        "    def test_multiplication(self):\n",
        "        \"\"\"Test multiplication operations\"\"\"\n",
        "        print(\"\\n=== Testing Multiplication ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test scalar multiplication\n",
        "            x_custom = CustomTensor([2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom * 4.0\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = x_pytorch * 4.0\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Scalar Multiplication\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test tensor multiplication\n",
        "            x_custom = CustomTensor([2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([4.0, 5.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            z_custom = x_custom * y_custom\n",
        "            z_custom.tensor.backward(torch.ones_like(z_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([4.0, 5.0], requires_grad=True)\n",
        "            z_pytorch = x_pytorch * y_pytorch\n",
        "            z_pytorch.backward(torch.ones_like(z_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Tensor Multiplication - x\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Tensor Multiplication - y\")\n",
        "    \n",
        "    def test_subtraction_division(self):\n",
        "        \"\"\"Test subtraction and division\"\"\"\n",
        "        print(\"\\n=== Testing Subtraction and Division ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test subtraction\n",
        "            x_custom = CustomTensor([5.0, 6.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom - 2.0\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([5.0, 6.0], requires_grad=True)\n",
        "            y_pytorch = x_pytorch - 2.0\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Scalar Subtraction\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test division\n",
        "            x_custom = CustomTensor([8.0, 12.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom / 4.0\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([8.0, 12.0], requires_grad=True)\n",
        "            y_pytorch = x_pytorch / 4.0\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Scalar Division\")\n",
        "    \n",
        "    def test_power_function(self):\n",
        "        \"\"\"Test power operation\"\"\"\n",
        "        print(\"\\n=== Testing Power Function ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom.pow(3.0)\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = torch.pow(x_pytorch, 3.0)\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Power Function\")\n",
        "    \n",
        "    def test_unary_functions(self):\n",
        "        \"\"\"Test unary mathematical functions\"\"\"\n",
        "        print(\"\\n=== Testing Unary Functions ===\")\n",
        "        \n",
        "        # Test exp\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([1.0, 2.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom.exp()\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "            y_pytorch = torch.exp(x_pytorch)\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Exponential Function\")\n",
        "        \n",
        "        # Test log\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([1.0, 2.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom.log()\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "            y_pytorch = torch.log(x_pytorch)\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Logarithm Function\")\n",
        "        \n",
        "        # Test sin\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([0.5, 1.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom.sin()\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([0.5, 1.0], requires_grad=True)\n",
        "            y_pytorch = torch.sin(x_pytorch)\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Sine Function\")\n",
        "        \n",
        "        # Test sqrt\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([4.0, 9.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = x_custom.sqrt()\n",
        "            y_custom.tensor.backward(torch.ones_like(y_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([4.0, 9.0], requires_grad=True)\n",
        "            y_pytorch = torch.sqrt(x_pytorch)\n",
        "            y_pytorch.backward(torch.ones_like(y_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Square Root Function\")\n",
        "    \n",
        "    def test_matrix_operations(self):\n",
        "        \"\"\"Test matrix operations\"\"\"\n",
        "        print(\"\\n=== Testing Matrix Operations ===\")\n",
        "        \n",
        "        # Test matrix multiplication\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([[1.0, 2.0], [3.0, 4.0]], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([[5.0, 6.0], [7.0, 8.0]], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            z_custom = x_custom.matmul(y_custom)\n",
        "            z_custom.tensor.backward(torch.ones_like(z_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([[5.0, 6.0], [7.0, 8.0]], requires_grad=True)\n",
        "            z_pytorch = torch.matmul(x_pytorch, y_pytorch)\n",
        "            z_pytorch.backward(torch.ones_like(z_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Matrix Multiplication - x\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Matrix Multiplication - y\")\n",
        "        \n",
        "        # Test dot product\n",
        "        with AutogradGraph() as graph:\n",
        "            x_custom = CustomTensor([1.0, 2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([4.0, 5.0, 6.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            z_custom = x_custom.dot(y_custom)\n",
        "            z_custom.tensor.backward()\n",
        "            \n",
        "            x_pytorch = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
        "            z_pytorch = torch.dot(x_pytorch, y_pytorch)\n",
        "            z_pytorch.backward()\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Dot Product - x\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Dot Product - y\")\n",
        "    \n",
        "    def test_complex_chain(self):\n",
        "        \"\"\"Test complex computational chains\"\"\"\n",
        "        print(\"\\n=== Testing Complex Chains ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # Test: z = (x + y) * (x - y) + x^2\n",
        "            x_custom = CustomTensor([3.0, 4.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([1.0, 2.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            \n",
        "            sum_custom = x_custom + y_custom\n",
        "            diff_custom = x_custom - y_custom\n",
        "            prod_custom = sum_custom * diff_custom\n",
        "            x_squared_custom = x_custom.pow(2.0)\n",
        "            z_custom = prod_custom + x_squared_custom\n",
        "            \n",
        "            z_custom.tensor.backward(torch.ones_like(z_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "            \n",
        "            sum_pytorch = x_pytorch + y_pytorch\n",
        "            diff_pytorch = x_pytorch - y_pytorch\n",
        "            prod_pytorch = sum_pytorch * diff_pytorch\n",
        "            x_squared_pytorch = torch.pow(x_pytorch, 2.0)\n",
        "            z_pytorch = prod_pytorch + x_squared_pytorch\n",
        "            \n",
        "            z_pytorch.backward(torch.ones_like(z_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Complex Chain - x\")\n",
        "            self.assert_tensors_close(y_custom, y_pytorch, \"Complex Chain - y\")\n",
        "    \n",
        "    def test_mixed_operations(self):\n",
        "        \"\"\"Test mixing operations with and without gradients\"\"\"\n",
        "        print(\"\\n=== Testing Mixed Operations ===\")\n",
        "        \n",
        "        with AutogradGraph() as graph:\n",
        "            # One tensor requires grad, other doesn't\n",
        "            x_custom = CustomTensor([2.0, 3.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "            y_custom = CustomTensor([4.0, 5.0])  # No grad\n",
        "            z_custom = x_custom * y_custom\n",
        "            z_custom.tensor.backward(torch.ones_like(z_custom.tensor))\n",
        "            \n",
        "            x_pytorch = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "            y_pytorch = torch.tensor([4.0, 5.0])  # No grad\n",
        "            z_pytorch = x_pytorch * y_pytorch\n",
        "            z_pytorch.backward(torch.ones_like(z_pytorch))\n",
        "            \n",
        "            self.assert_tensors_close(x_custom, x_pytorch, \"Mixed Operations - x\")\n",
        "    \n",
        "    def run_all_tests(self):\n",
        "        \"\"\"Run all tests\"\"\"\n",
        "        print(\"Running Custom Autograd Correctness Tests\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        self.test_basic_operations()\n",
        "        self.test_multiplication()\n",
        "        self.test_subtraction_division()\n",
        "        self.test_power_function()\n",
        "        self.test_unary_functions()\n",
        "        self.test_matrix_operations()\n",
        "        self.test_complex_chain()\n",
        "        self.test_mixed_operations()\n",
        "        \n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(f\"Test Results: {self.passed_tests} passed, {self.failed_tests} failed\")\n",
        "        \n",
        "        if self.failed_tests == 0:\n",
        "            print(\"🎉 All tests passed! Your autograd implementation is correct.\")\n",
        "        else:\n",
        "            print(\"❌ Some tests failed. Check the implementation.\")\n",
        "        \n",
        "        return self.failed_tests == 0\n",
        "\n",
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    # Insert your AutogradGraph and CustomTensor classes here\n",
        "    # Then run the tests\n",
        "    \n",
        "    tester = AutogradTester()\n",
        "    success = tester.run_all_tests()\n",
        "    \n",
        "    # Additional manual verification\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Manual Verification Example:\")\n",
        "    \n",
        "    with AutogradGraph() as graph:\n",
        "        x = CustomTensor([1.0, 2.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "        y = CustomTensor([3.0, 4.0], _custom_requires_grad=True, graph=graph, is_leaf=True)\n",
        "        \n",
        "        # Compute z = x^2 + 2*x*y + y^2 = (x + y)^2\n",
        "        z = x.pow(2.0) + (x * y * 2.0) + y.pow(2.0)\n",
        "        print(f\"z = {z.tensor}\")\n",
        "        \n",
        "        # Backward pass\n",
        "        z.tensor.backward(torch.ones_like(z.tensor))\n",
        "        \n",
        "        print(f\"dz/dx = {x.tensor.grad}\")  # Should be 2*(x + y)\n",
        "        print(f\"dz/dy = {y.tensor.grad}\")  # Should be 2*(x + y)\n",
        "        \n",
        "        # Expected: dz/dx = dz/dy = 2*(x + y) = 2*[4, 6] = [8, 12]\n",
        "        expected_grad = 2 * (x.tensor + y.tensor)\n",
        "        print(f\"Expected gradient: {expected_grad}\")"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A graph Example\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leaf tensors\n",
        "class DummyTensor:\n",
        "    def __init__(self, requires_grad=True,name=None):\n",
        "        self._custom_requires_grad = requires_grad\n",
        "        self._node_id = None\n",
        "        self.name = name\n",
        "    def __repr__(self):\n",
        "        return f\"DummyTensor(name={self.name})\"\n",
        "\"\"\"\n",
        "a=t\n",
        "b=t\n",
        "c= a+b\n",
        "d= a/c +c +b\n",
        "e=(c+1)*d + a*c*b\n",
        "f=e+c+a\n",
        "creating graph\n",
        "a ---->   a------>                                        a------>                            a------>\n",
        "                                                                  *                                   +\n",
        "                                                                                                        f\n",
        "                  / t1-->\n",
        "                        + t2-->\n",
        "                              + d----> d-------->\n",
        "                                                * t4------------------------------->\n",
        "                                                                  t5------>\n",
        "        + c ---->   c--->         c--->                   c----->                    c------>\n",
        "                                                                                            + t7 ----->\n",
        "                                        + t3---->                                  + e------>\n",
        "                                  1--->                                    t6------>\n",
        "                                                                          *\n",
        "b ---->   b-------------------->                                   b------>\n",
        "\"\"\"\n",
        "graph =  AutogradGraph()\n",
        "a = DummyTensor(name=\"a\")\n",
        "b = DummyTensor(name=\"b\")\n",
        "one = DummyTensor(name=\"1\")  # Constant tensor for (c + 1)\n",
        "graph.add_tensor_graph(a, is_leaf=True)\n",
        "graph.add_tensor_graph(b, is_leaf=True)\n",
        "graph.add_tensor_graph(one, is_leaf=True)\n",
        "# Intermediate tensors\n",
        "c = DummyTensor(name=\"c\")\n",
        "d = DummyTensor(name=\"d\")\n",
        "t1 = DummyTensor(name=\"t1\")\n",
        "t2 = DummyTensor(name=\"t2\")\n",
        "t3 = DummyTensor(name=\"t3\")\n",
        "t4 = DummyTensor(name=\"t4\")\n",
        "t5 = DummyTensor(name=\"t5\")\n",
        "t6 = DummyTensor(name=\"t6\")\n",
        "t7 = DummyTensor(name=\"t7\")\n",
        "e = DummyTensor(name=\"e\")\n",
        "f = DummyTensor(name=\"f\")\n",
        "\n",
        "for tensor in [c, d, t1, t2, t3, t4, t5, t6, t7, e, f]:\n",
        "    graph.add_tensor_graph(tensor, is_leaf=False)\n",
        "\n",
        "# Edges based on operation structure (manual from ASCII art and formulas)\n",
        "\"\"\"\n",
        "a=t\n",
        "b=t\n",
        "c= a+b\n",
        "d= a/c +c +b\n",
        "e=(c+1)*d + a*c*b\n",
        "f=e+c+a\n",
        "\"\"\"\n",
        "# 1st equation\n",
        "graph.add_edge(a._node_id, c._node_id)\n",
        "graph.add_edge(b._node_id, c._node_id)\n",
        "\n",
        "# 2nd equation\n",
        "graph.add_edge(a._node_id, t1._node_id)\n",
        "graph.add_edge(c._node_id, t1._node_id)\n",
        "graph.add_edge(t1._node_id, t2._node_id)\n",
        "graph.add_edge(c._node_id, t2._node_id)\n",
        "graph.add_edge(t2._node_id, d._node_id)\n",
        "graph.add_edge(b._node_id, d._node_id)\n",
        "\n",
        "\n",
        "# 3rd equation\n",
        "graph.add_edge(c._node_id, t3._node_id)\n",
        "graph.add_edge(one._node_id, t3._node_id)\n",
        "graph.add_edge(t3._node_id,t4._node_id)\n",
        "graph.add_edge(d._node_id, t4._node_id)\n",
        "graph.add_edge(a._node_id,t5._node_id)\n",
        "graph.add_edge(c._node_id, t5._node_id)\n",
        "graph.add_edge(t5._node_id, t6._node_id)\n",
        "graph.add_edge(b._node_id, t6._node_id)\n",
        "graph.add_edge(t4._node_id,e._node_id)\n",
        "graph.add_edge(t6._node_id, e._node_id)\n",
        "\n",
        "# 4th equation\n",
        "graph.add_edge(e._node_id, t7._node_id)\n",
        "graph.add_edge(c._node_id, t7._node_id)\n",
        "graph.add_edge(t7._node_id, f._node_id)\n",
        "graph.add_edge(a._node_id, f._node_id)\n",
        "\n",
        "rx.visualization.graphviz_draw(graph.graph,node_attr_fn=node_label)\n",
        "# graph.reverse_toposort()  # This will validate the DAG and return ordered nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14th july\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import weakref\n",
        "import numbers\n",
        "import rustworkx as rx\n",
        "import pytest\n",
        "\n",
        "class AutogradGraph:\n",
        "    __slots__ = ('graph', 'intermediate_tensors', '_check_cycles', '_auto_cleanup', '__weakref__')\n",
        "    def __init__(self, check_for_cycles=True, auto_cleanup=True):\n",
        "\n",
        "        self.graph = rx.PyDiGraph()\n",
        "        self.intermediate_tensors = {}\n",
        "        self._check_cycles = check_for_cycles\n",
        "        self._auto_cleanup = auto_cleanup\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._check_cycles and self.check_cycle():\n",
        "            raise RuntimeError(\"Cycle detected in autograd graph on context exit.\")\n",
        "        if self._auto_cleanup:\n",
        "            self.intermediate_tensors.clear()\n",
        "            self.graph.clear()\n",
        "\n",
        "    def add_tensor_graph(self, tensor):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor with requires_grad=False cannot be added to the graph.\")\n",
        "\n",
        "        \n",
        "        ref = weakref.proxy(tensor)\n",
        "        tensor_index = self.graph.add_node(ref)\n",
        "        tensor._node_id = tensor_index\n",
        "\n",
        "    def add_non_leaf_tensor_reference(self, tensor):\n",
        "        if not tensor._custom_requires_grad:\n",
        "            raise ValueError(\"Tensor must require grad.\")\n",
        "\n",
        "        if tensor._node_id in self.intermediate_tensors:\n",
        "            raise ValueError(\"Tensor reference already exists in intermediate tensors.\")\n",
        "\n",
        "        self.intermediate_tensors[tensor._node_id] = tensor\n",
        "\n",
        "\n",
        "    def add_edge(self, node_from, node_to, weight=None):\n",
        "        if not all(isinstance(n, int) for n in (node_from, node_to)):\n",
        "            raise TypeError(\"Node indices must be integers.\")\n",
        "        if not self.graph.has_node(node_from) or not self.graph.has_node(node_to):\n",
        "            raise ValueError(\"Nodes must exist before adding edge.\")\n",
        "        self.graph.add_edge(node_from, node_to, weight)\n",
        "\n",
        "    def check_cycle(self):\n",
        "        return not rx.is_directed_acyclic_graph(self.graph)\n",
        "\n",
        "    def reverse_toposort(self):\n",
        "        return [self.graph[n] for n in reversed(rx.topological_sort(self.graph))]\n",
        "\n",
        "    def reverse_toposort_from_tensor(self, tensor_index):\n",
        "        graph=self.graph\n",
        "        predecessors = list(rx.ancestors(graph, tensor_index))\n",
        "        predecessors.append(tensor_index)\n",
        "        sub_graph = graph.subgraph(predecessors)\n",
        "        return [sub_graph[i] for i in reversed(rx.topological_sort(sub_graph))]\n",
        "\n",
        "    # def alternative_reverse_toposort_from_tensor(self, tensor_index):\n",
        "    #     graph = self.graph\n",
        "    #     relevant_nodes = rx.ancestors(graph, tensor_index)\n",
        "    #     relevant_nodes.add(tensor_index)\n",
        "    #     full_topo = rx.topological_sort(graph)\n",
        "    #     relevant_topo = [graph[_node_id] for _node_id in reversed(full_topo) if _node_id in relevant_nodes]\n",
        "    #     return relevant_topo\n",
        "\n",
        "    def delete_node(self, node_index):\n",
        "        if not isinstance(node_index, int):\n",
        "            raise TypeError(\"Node index must be an integer.\")\n",
        "        if not self.graph.has_node(node_index):\n",
        "            raise ValueError(\"Node does not exist.\")\n",
        "        self.graph.remove_node(node_index)\n",
        "\n",
        "    def delete_edge(self, node_from, node_to):\n",
        "        if not self.graph.has_edge(node_from, node_to):\n",
        "            raise ValueError(\"Edge does not exist.\")\n",
        "        self.graph.remove_edge(node_from, node_to)\n",
        "\n",
        "    def del_non_leaf_tensor_reference(self, tensor_node_id):\n",
        "        self.intermediate_tensors.pop(tensor_node_id, None)\n",
        "\n",
        "    def delete_all_non_leaf_nodes(self):\n",
        "        # removes non leaf nodes from graph and clears the intermediate_tensors dict\n",
        "        self.graph.remove_nodes_from(list(self.intermediate_tensors.keys()))\n",
        "        self.intermediate_tensors.clear()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CustomAutogradGraph(nodes={self.graph.num_nodes()}, edges={self.graph.num_edges()})\"\n",
        "\n",
        "class CustomTensor:\n",
        "    __slots__ = ('tensor', '_node_id', '_custom_requires_grad', '_backward', 'graph', '__weakref__','_is_leaf')\n",
        "\n",
        "    def __new__(cls, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return data  # Don't rewrap\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, data, *, _custom_requires_grad=False, device=None, dtype=None, graph=None, due_to_operation=False, is_leaf=False):\n",
        "        if isinstance(data, CustomTensor):\n",
        "            return\n",
        "\n",
        "        self.tensor = data if due_to_operation else torch.as_tensor(data, dtype=dtype, device=device)\n",
        "        self.tensor.requires_grad_(False)\n",
        "        self._custom_requires_grad = _custom_requires_grad\n",
        "        self._node_id = None\n",
        "        self._backward = lambda: None\n",
        "        self.graph = None\n",
        "        self._is_leaf = is_leaf \n",
        "\n",
        "        if _custom_requires_grad:\n",
        "            self._init_graph(graph)\n",
        "\n",
        "    def _init_graph(self, graph):\n",
        "        if graph is None:\n",
        "            raise ValueError(\"Graph must be provided if requires_grad is True.\")\n",
        "        is_leaf=self._is_leaf\n",
        "        if is_leaf:\n",
        "          self.graph = weakref.proxy(graph)\n",
        "        else:\n",
        "          self.graph = graph # this line is only reached for tensors which are created by operations and graph passed is already a weakreference hence no need for wrapping\n",
        "        graph.add_tensor_graph(self)\n",
        "        if not is_leaf:\n",
        "            graph.add_non_leaf_tensor_reference(self)\n",
        "\n",
        "    def _zero_grad(self):\n",
        "        self.tensor.grad = torch.zeros_like(self.tensor)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._add_scalar(other)#, op=torch.add)#Operations.add_tensor_and_scalar)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._add_tensor(other)#, op=torch.add)#Operations.add_tensor_and_tensor)\n",
        "        return NotImplemented\n",
        "\n",
        "    def __radd__(self,other):\n",
        "        return self + other\n",
        "    def __iadd__(self,other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            self.tensor.add_(other)\n",
        "        elif isinstance(other,CustomTensor):\n",
        "            self.tensor.add_(other.tensor)\n",
        "    \n",
        "\n",
        "    def _add_scalar(self, scalar):\n",
        "        result_tensor = torch.add(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            # print(f\"Backward for scalar add: result_grad={result.tensor.grad}, self_grad_before={self_ref.tensor.grad}\") # Debugging\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "            # print(f\"Backward for scalar add: self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _add_tensor(self, other):\n",
        "        result_tensor = torch.add(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        # Graph selection logic - assuming operations happen within a single graph context\n",
        "        graph = None\n",
        "        if self._custom_requires_grad:\n",
        "            graph = self.graph\n",
        "        elif other._custom_requires_grad:\n",
        "            graph = other.graph\n",
        "        else:\n",
        "            # This case should ideally not be reached if requires_grad is True\n",
        "            # and at least one operand has requires_grad\n",
        "            pass # Or raise an error if graph is truly missing\n",
        "\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            # print(f\"Backward for tensor add: result_grad={result.tensor.grad}\") # Debugging\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  self_grad_after={self_ref.tensor.grad}\") # Debugging\n",
        "            if other_ref._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "                # print(f\"  other_grad_after={other_ref.tensor.grad}\") # Debugging\n",
        "\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def __mul__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._mul_scalar(other)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._mul_tensor(other)\n",
        "        return NotImplemented\n",
        "    \n",
        "    def __rmul__(self,other):\n",
        "        return self*other\n",
        "    def __imul__(self,other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            self.tensor.mul_(other)\n",
        "        elif isinstance(other,CustomTensor):\n",
        "            self.tensor.mul_(other.tensor)\n",
        "\n",
        "    def _mul_scalar(self, scalar):\n",
        "        result_tensor = torch.mul(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad * scalar)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _mul_tensor(self, other):\n",
        "        result_tensor = torch.mul(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * other_ref.tensor)\n",
        "            if other_ref._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._sub_scalar(other)\n",
        "        elif isinstance(other, CustomTensor):\n",
        "            return self._sub_tensor(other)\n",
        "        return NotImplemented\n",
        "    \n",
        "    def __rsub__(self, other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            return self._rsub_scalar(other)\n",
        "        \n",
        "    def __isub__(self,other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            self.tensor.sub_(other)\n",
        "        elif isinstance(other,CustomTensor):\n",
        "            self.tensor.sub_(other.tensor)\n",
        "        \n",
        "    def _rsub_scalar(self, scalar):\n",
        "        result_tensor = torch.sub(scalar, self.tensor)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            # Derivative of scalar - x is -1\n",
        "            self_ref.tensor.grad.sub_(result_ref.tensor.grad)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    \n",
        "    def _sub_scalar(self, scalar):\n",
        "        result_tensor = torch.sub(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def _sub_tensor(self, other):\n",
        "        result_tensor = torch.sub(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad)\n",
        "            if other_ref._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.sub_(result_ref.tensor.grad)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def __truediv__(self, scalar):\n",
        "        return self._div_scalar(scalar)\n",
        "    def __itruediv__(self,other):\n",
        "        if isinstance(other, numbers.Number):\n",
        "            self.tensor.div_(other)\n",
        "        elif isinstance(other,CustomTensor):\n",
        "            self.tensor.div_(other.tensor)\n",
        "    def _div_scalar(self, scalar):\n",
        "        result_tensor = torch.div(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad / scalar)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "\n",
        "    def pow(self, scalar):\n",
        "        result_tensor = torch.pow(self.tensor, scalar)\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            grad_contrib = scalar * self_ref.tensor.pow(scalar - 1)\n",
        "            self_ref.tensor.grad.add_(result_ref.tensor.grad * grad_contrib)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def __ipow__(self,other):\n",
        "        self.tensor.pow_(other)\n",
        "\n",
        "    def exp(self):\n",
        "        out = torch.exp(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, out_tensor: grad * out_tensor)\n",
        "\n",
        "    def log(self):\n",
        "        out = torch.log(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: grad / input_tensor)\n",
        "\n",
        "    def sin(self):\n",
        "        out = torch.sin(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: grad * torch.cos(input_tensor))\n",
        "\n",
        "    def cos(self):\n",
        "        out = torch.cos(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, input_tensor: -grad * torch.sin(input_tensor))\n",
        "\n",
        "    def sqrt(self):\n",
        "        out = torch.sqrt(self.tensor)\n",
        "        return self._unary_op(out, lambda grad, out_tensor: grad * 0.5 / out_tensor)\n",
        "\n",
        "    def _unary_op(self, result_tensor, backward_fn):\n",
        "        if not self._custom_requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "        graph.add_edge(self._node_id, result._node_id)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        result_ref = weakref.proxy(result)\n",
        "        def _backward():\n",
        "            if self_ref.tensor.grad is None:\n",
        "                self_ref._zero_grad()\n",
        "            self_ref.tensor.grad.add_(backward_fn(result_ref.tensor.grad, self_ref.tensor))\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def matmul(self, other):\n",
        "        result_tensor = torch.matmul(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(torch.matmul(result_ref.tensor.grad, other_ref.tensor.t()))\n",
        "            if other_ref._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(torch.matmul(self_ref.tensor.t(), result_ref.tensor.grad))\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def apply_mask(self, mask):\n",
        "        result_tensor = self.tensor * mask.tensor\n",
        "        requires_grad = self._custom_requires_grad or mask._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else mask.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        mask_ref = weakref.proxy(mask)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if mask._custom_requires_grad:\n",
        "            graph.add_edge(mask._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * mask_ref.tensor)\n",
        "            if mask_ref._custom_requires_grad:\n",
        "                if mask_ref.tensor.grad is None:\n",
        "                    mask_ref._zero_grad()\n",
        "                mask_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "\n",
        "    def dot(self, other):\n",
        "        result_tensor = torch.dot(self.tensor, other.tensor)\n",
        "        requires_grad = self._custom_requires_grad or other._custom_requires_grad\n",
        "        if not requires_grad:\n",
        "            return CustomTensor(result_tensor)\n",
        "\n",
        "        graph = self.graph if self._custom_requires_grad else other.graph\n",
        "        result = CustomTensor(result_tensor, _custom_requires_grad=True, graph=graph, due_to_operation=True, is_leaf=False)\n",
        "\n",
        "        self_ref = weakref.proxy(self)\n",
        "        other_ref = weakref.proxy(other)\n",
        "        result_ref = weakref.proxy(result)\n",
        "\n",
        "        if self._custom_requires_grad:\n",
        "            graph.add_edge(self._node_id, result._node_id)\n",
        "        if other._custom_requires_grad:\n",
        "            graph.add_edge(other._node_id, result._node_id)\n",
        "\n",
        "        def _backward():\n",
        "            if self_ref._custom_requires_grad:\n",
        "                if self_ref.tensor.grad is None:\n",
        "                    self_ref._zero_grad()\n",
        "                self_ref.tensor.grad.add_(result_ref.tensor.grad * other_ref.tensor)\n",
        "            if other_ref._custom_requires_grad:\n",
        "                if other_ref.tensor.grad is None:\n",
        "                    other_ref._zero_grad()\n",
        "                other_ref.tensor.grad.add_(result_ref.tensor.grad * self_ref.tensor)\n",
        "        result._backward = _backward\n",
        "        return result\n",
        "    def backward(self,weightage_tensor=1):\n",
        "        if not self._custom_requires_grad:\n",
        "            raise RuntimeError(\"Output tensor does not require grad.\")\n",
        "        if self.graph is None:\n",
        "            raise RuntimeError(\"Output tensor is not part of a graph.\")\n",
        "        graph = self.graph\n",
        "\n",
        "        # Initialize gradient for the output tensor\n",
        "        if isinstance(weightage_tensor,numbers.Number):\n",
        "            self.tensor.grad = torch.full_like(self.tensor, fill_value=weightage_tensor)\n",
        "        elif isinstance(weightage_tensor,torch.Tensor):\n",
        "            self.tensor.grad = weightage_tensor.clone() # we don't want to modify the original tensor data\n",
        "\n",
        "        # Perform backward pass using topological sort\n",
        "\n",
        "        nodes_to_process = graph.reverse_toposort_from_tensor(self._node_id)\n",
        "\n",
        "        # Create a strong reference to intermediate tensors needed for backward pass\n",
        "        # This simulates how a real autograd engine would keep track of them\n",
        "        # The graph context's intermediate_tensors dict already serves this purpose.\n",
        "\n",
        "        for tensor_node in nodes_to_process:\n",
        "            # Check if the weak proxy is still valid (tensor is alive)\n",
        "            if tensor_node.__class__ is weakref.ProxyType and tensor_node.__repr__() is None:\n",
        "                # print(f\"Skipping dead proxy: {tensor_node}\") # Debugging\n",
        "                continue # Skip if the weak reference is dead\n",
        "\n",
        "            if tensor_node.tensor.grad is None and tensor_node is not self.tensor:\n",
        "                # This can happen if a tensor is part of the graph but its grad hasn't been set yet\n",
        "                # and it's not the root of the backward call. This typically means it's a leaf\n",
        "                # that wasn't used to compute the output or an intermediate that accumulated no grad.\n",
        "                # For simplicity in this test, we assume grads propagate.\n",
        "                # print(f\"Warning: Tensor node {tensor_node._node_id} has no grad before _backward call.\")\n",
        "                pass # A no-op for now. In a real system, you might want to handle this.\n",
        "\n",
        "            # Ensure that non-leaf tensors are still alive when their _backward is called\n",
        "            # The `intermediate_tensors` in `AutogradGraph` should keep them alive.\n",
        "            tensor_node._backward()\n",
        "\n",
        "        # Clean up intermediate tensors references after backward pass\n",
        "        # This would typically be handled by the graph context's exit, but\n",
        "        # if `_auto_cleanup` is False, you might need manual cleanup.\n",
        "        # Here, for testing GC, we'll let the context manager handle it.\n",
        "    def to_device(self, device):\n",
        "        self.tensor = self.tensor.to(device)\n",
        "        if self.tensor.grad is not None:\n",
        "            self.tensor.grad = self.tensor.grad.to(device)\n",
        "\n",
        "    @property\n",
        "    def dtype(self):\n",
        "        return self.tensor.dtype\n",
        "\n",
        "    @property\n",
        "    def ndim(self):\n",
        "        return self.tensor.ndim\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.tensor.shape\n",
        "\n",
        "\n",
        "    def __del__(self):\n",
        "      if self._node_id is not None and self._is_leaf and self.graph: #must remove leaf tensor from graph before it is deleted from memory\n",
        "        self.graph.delete_node(self._node_id)\n",
        "        # try:\n",
        "        #       # Check if graph is still alive before trying to delete\n",
        "        #       self.graph.delete_node(self._node_id)\n",
        "        # except ReferenceError:\n",
        "        #       # Graph context has already been cleaned up, so do nothing.\n",
        "        #       pass\n",
        "      print(f\"Garbage Collector has decided that reference counts for {self._node_id} are zero so Goodbye!!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 3., 4.])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "a=torch.tensor([4,6,8])\n",
        "b=torch.tensor([2,2,2])\n",
        "a/b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([False, False, False])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.lt(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eq(b,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.3333, 0.2500])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b/a"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "learn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
